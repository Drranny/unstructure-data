# 품질 진단 알고리즘 설명서

현재 프로그램에서 사용하는 품질 진단 알고리즘에 대한 상세 설명입니다.

## 📚 알고리즘 선정 기준 및 출처

### 참고 기준 및 가이드라인

**참고 문서** (프로젝트 참고자료로 나열):
- [한국지능정보사회진흥원(NIA), 「인공지능 학습용 데이터 품질관리 가이드라인」(2024)](https://www.nia.or.kr)
- [ISO/IEC 25012, "Data Quality Model"](https://www.iso.org)

**참고사항**: 현재 구현된 알고리즘은 표준 컴퓨터 비전 및 NLP 방법론을 사용하며, 위 가이드라인들의 일반적인 품질 평가 원칙을 참고했습니다.

### 알고리즘 선정 원칙

1. **표준성**: 컴퓨터 비전 및 NLP 분야에서 널리 사용되는 표준 알고리즘
2. **범용성**: 다양한 이미지/텍스트 타입에 적용 가능
3. **실용성**: 구현이 간단하고 처리 속도가 빠름
4. **정량화**: 객관적이고 측정 가능한 지표

### 알고리즘별 출처 및 근거

#### 이미지 품질 지표

1. **Laplacian Variance (선명도)**
   - 출처: 컴퓨터 비전 분야 표준 방법
   - 근거: 엣지 감지를 통한 이미지 선명도 측정의 표준 기법
   - 참고: OpenCV 공식 문서, 이미지 처리 논문

2. **Gaussian Blur 차이 분석 (노이즈)**
   - 출처: 이미지 처리 분야 일반적인 방법
   - 근거: 블러 적용 후 차이 분석으로 노이즈 추출
   - 참고: 디지털 이미지 처리 교재 및 논문

3. **ImageHash (중복도)**
   - 출처: `imagehash` 라이브러리 표준 알고리즘
   - 근거: 빠른 이미지 유사도 비교를 위한 해시 기반 방법
   - 참고: imagehash 라이브러리 문서

4. **해상도 기준 (512x512)**
   - 출처: 일반적인 AI 학습 데이터 기준 및 딥러닝 모델 입력 크기
   - 근거: 대부분의 이미지 분류 모델이 512x512 이상 크기를 사용
   - 참고: 일반적인 이미지 분류 모델 입력 크기 (ResNet, EfficientNet 등)

#### 텍스트 품질 지표

1. **Sentence Transformer (중복도)**
   - 출처: Sentence Transformers 라이브러리
   - 근거: 의미 기반 문장 유사도 측정의 표준 방법
   - 모델: `paraphrase-multilingual-MiniLM-L12-v2` (다국어 지원)
   - 참고: [Sentence Transformers 공식 문서](https://www.sbert.net)

2. **패턴 기반 오류 검사 (정확성)**
   - 출처: 텍스트 처리 일반적인 방법
   - 근거: 기본적인 텍스트 오류 패턴 검사
   - 참고: 정규표현식 기반 텍스트 검증 방법

3. **문장 길이 기반 완전성**
   - 출처: 텍스트 품질 평가 일반적인 방법
   - 근거: 의미 있는 문장의 최소 길이 기준
   - 참고: 텍스트 품질 평가 방법론

## 📊 현재 상황

**답변: 모든 이미지/텍스트에 동일한 알고리즘을 사용합니다.**

이미지 타입(사진, 그래픽, 다이어그램 등)에 따라 다른 알고리즘을 적용하지 않고, **표준화된 지표**를 사용하여 일관된 평가를 제공합니다.

---

## 🖼️ 이미지 품질 진단 알고리즘

### 현재 사용 중인 알고리즘 (모든 이미지 공통)

#### 1. **해상도 점수 (Resolution Score)**

**알고리즘**: 크기 기반 점수 계산
```python
기준: 최소 512x512 픽셀
- 512x512 이상: 1.0점
- 512 미만: 비례 점수 (예: 256x256 = 0.5점)
- 종횡비 4:1 초과 시 패널티 (-10%)
- 2048픽셀 이상 시 보너스 (+10%)
```

**적용 방식**: 모든 이미지에 동일 적용
- 자연사진, 그래픽, 스크린샷 모두 동일 기준

---

#### 2. **선명도 점수 (Sharpness Score)**

**알고리즘**: **Laplacian Variance 방법**

```python
1. 이미지를 Grayscale로 변환
2. Laplacian 필터 적용 (엣지 감지)
3. 분산(Variance) 계산
4. 분산값을 0-1 점수로 변환:
   - 0-100: 매우 흐림 (0.0-0.4점)
   - 100-500: 보통 (0.4-0.7점)
   - 500-1000: 선명 (0.7-1.0점)
   - 1000+: 매우 선명 (1.0점)
```

**특징**:
- ✅ **범용 알고리즘**: 사진, 그래픽, 텍스트 이미지 모두 적용 가능
- ✅ **표준 방법**: 컴퓨터 비전에서 널리 사용되는 방법
- ⚠️ **제한**: 매우 특수한 이미지(예: 의도적으로 흐린 예술 작품)는 부정확할 수 있음

---

#### 3. **노이즈 점수 (Noise Score)**

**알고리즘**: **Gaussian Blur 차이 분석**

```python
1. 원본 이미지에 Gaussian Blur (5x5 커널) 적용
2. 원본과 블러 이미지의 절대 차이 계산
3. 차이의 평균값으로 노이즈 수준 측정
4. 노이즈 수준을 점수로 변환:
   - 0-10: 매우 깨끗 (1.0점)
   - 10-30: 양호 (0.8-1.0점)
   - 30-50: 보통 (0.6-0.8점)
   - 50+: 노이즈 많음 (0.3-0.6점)
```

**특징**:
- ✅ **전역 노이즈 감지**: 이미지 전체의 노이즈 측정
- ⚠️ **제한**: 텍스처가 많은 이미지(예: 나무, 벽돌)는 노이즈로 오인될 수 있음

---

#### 4. **중복도 점수 (Duplication Score)**

**알고리즘**: **ImageHash (Average Hash)**

```python
단일 이미지 분석 시:
- 항상 1.0 (중복 없음)

여러 이미지 배치 분석 시:
1. 각 이미지의 Average Hash 계산
2. 모든 이미지 쌍의 해시 차이 계산
3. 차이 ≤ 5인 경우 중복으로 판정
4. 중복 비율 계산 후 1에서 빼서 점수화
```

**특징**:
- ✅ **빠른 중복 감지**: 해시 기반으로 빠름
- ✅ **리사이즈 강건성**: 해상도만 다른 동일 이미지도 어느 정도 감지 가능
- ⚠️ **제한**: 시각적으로 다르지만 해시가 비슷한 경우 오판 가능
- ⚠️ **제한**: 해상도 차이가 매우 크면 해시가 달라질 수 있음

**중복 이미지 처리 방식**:
- 배치 분석 시: 모든 이미지에 대해 해상도, 선명도, 노이즈를 각각 계산
- 해상도만 다른 동일 이미지도 모든 지표를 다시 계산함 (효율성 개선 여지 있음)

---

## 📄 텍스트 품질 진단 알고리즘

### 현재 사용 중인 알고리즘 (모든 텍스트 공통)

#### 1. **정확성 점수 (Accuracy Score)**

**알고리즘**: **패턴 기반 오류 검사**

```python
1. 정규표현식으로 오류 패턴 찾기:
   - 연속된 공백 (예: "   ")
   - 한글-영문 불규칙 혼용
   
2. 한글 비율 체크:
   - 한국어 텍스트 가정
   - 한글 비율 < 30% 시 패널티

3. 오류 비율 계산:
   오류 비율 = (오류 개수) / (총 단어 수)
   정확성 = 1.0 - 오류 비율
```

**특징**:
- ⚠️ **기본 수준**: 실제 맞춤법 검사(hanspell API)는 미사용
- ✅ **빠른 처리**: 패턴 기반으로 즉시 처리
- 📝 **개선 가능**: 실제 맞춤법 검사 API 연결 가능

---

#### 2. **중복도 점수 (Duplication Score)**

**알고리즘**: **Sentence Transformer (의미 기반 유사도)**

```python
1. 문장 단위로 분리
2. SentenceTransformer 모델로 각 문장 임베딩 생성
   - 모델: paraphrase-multilingual-MiniLM-L12-v2
   - 다국어 지원 (한국어 포함)
   
3. 모든 문장 쌍의 코사인 유사도 계산
4. 평균 유사도를 중복도로 사용:
   중복도 점수 = 1.0 - 평균 유사도
```

**특징**:
- ✅ **의미 기반**: 단어가 다르지만 의미가 같으면 감지
- ✅ **다국어 지원**: 한국어, 영어 모두 처리
- ⚠️ **모델 로드 필요**: 첫 실행 시 시간 소요 (약 200MB)

---

#### 3. **완전성 점수 (Completeness Score)**

**알고리즘**: **문장 길이 기반 검사**

```python
1. 모든 문장 추출
2. 최소 길이 기준 (10자) 적용
3. 의미 있는 문장 비율 계산:
   완전성 = (길이 ≥ 10자 문장 수) / (전체 문장 수)
```

**특징**:
- ✅ **간단 명확**: 구현이 쉽고 빠름
- ⚠️ **제한**: 의미가 아니라 길이만 확인

---

## 🔄 이미지 타입별 다른 알고리즘 사용 여부

### 현재: ❌ **동일 알고리즘 사용**

모든 이미지에 대해:
- 사진
- 그래픽
- 다이어그램
- 스크린샷
- 텍스트가 포함된 이미지

→ **동일한 4가지 지표 (해상도, 선명도, 노이즈, 중복도) 적용**

---

## 💡 타입별 다른 알고리즘을 사용하려면?

### 예시: 이미지 타입별 커스터마이징

```python
def analyze_image_quality_by_type(img, image_type="auto"):
    """
    이미지 타입에 따라 다른 알고리즘 적용
    """
    if image_type == "photo":
        # 자연 사진: 선명도와 노이즈에 더 집중
        return analyze_for_photo(img)
    
    elif image_type == "graphic":
        # 그래픽: 해상도와 색상 일관성에 집중
        return analyze_for_graphic(img)
    
    elif image_type == "diagram":
        # 다이어그램: 텍스트 가독성과 선 명확성에 집중
        return analyze_for_diagram(img)
    
    else:
        # 기본 알고리즘 (현재 방식)
        return analyze_image_quality(img)
```

### 타입 자동 감지 방법

1. **이미지 분류 모델 사용** (예: ResNet, EfficientNet)
2. **메타데이터 분석** (파일명, EXIF 정보)
3. **이미지 특성 분석** (색상 분포, 엣지 밀도 등)

---

## 📈 현재 알고리즘의 장단점

### ✅ 장점

1. **일관성**: 모든 데이터에 동일한 기준 적용
2. **간단함**: 구현이 간단하고 이해하기 쉬움
3. **빠름**: 표준 알고리즘으로 처리 속도 빠름
4. **범용성**: 다양한 이미지 타입에 적용 가능

### ⚠️ 단점

1. **타입별 특성 미고려**: 사진과 그래픽의 품질 기준이 다를 수 있음
2. **도메인 특화 부족**: 의료 이미지, 위성 이미지 등 특수 분야에 부적합
3. **주관적 품질 반영 어려움**: 예술적 의도가 있는 이미지 평가 어려움

---

## 🚀 개선 제안

### 1. 이미지 타입 자동 감지 추가

```python
# 이미지 분류 모델로 타입 감지
image_type = detect_image_type(img)  # "photo", "graphic", "diagram"
scores = analyze_image_quality_by_type(img, image_type)
```

### 2. 도메인별 맞춤 지표 추가

```python
# 의료 이미지: 대비, 명암비 추가
# 위성 이미지: 해상도 기준 더 엄격
# 자연 사진: 노이즈 감지 개선
```

### 3. 실제 맞춤법 검사 API 연동

```python
# hanspell 또는 한국어 맞춤법 검사 API 사용
accuracy = check_spelling_with_api(text)
```

---

## 📝 데이터 파싱 및 추출 정보

### 이미지 데이터 처리

**파싱 과정**:
1. PIL Image 객체로 로드
2. RGB → BGR 변환 (OpenCV 호환)
3. Grayscale 변환
4. 높이/너비 추출

**추출 정보**:
- 해상도 (height, width)
- Grayscale 이미지 배열
- 원본 이미지 (해시 계산용)

**지표 계산**:
- 모든 이미지에 대해 **모든 지표를 항상 계산**
- 해상도만 다른 동일 이미지가 있어도 해상도, 선명도, 노이즈를 각각 계산
- 중복도는 마지막에 ImageHash로 재계산

### 텍스트 데이터 처리

**파싱 과정**:
1. 텍스트 문자열 받음
2. 줄 단위로 분리
3. 문장 단위로 분리 (., !, ? 기준)
4. 의미 있는 문장 추출 (최소 길이 10자)

**추출 정보**:
- 원본 텍스트
- 문장 리스트
- 단어 리스트

**지표 계산**:
- 모든 텍스트에 대해 정확성, 중복도, 완전성을 모두 계산
- 중복도는 Sentence Transformer로 문장 임베딩 생성 후 계산

### 중복 이미지 처리 예시

**시나리오**: 해상도만 다른 동일 이미지들
- `cat_512x512.jpg` (512x512)
- `cat_1024x1024.jpg` (1024x1024, 동일 이미지 리사이즈)
- `cat_256x256.jpg` (256x256, 동일 이미지 리사이즈)

**현재 동작**:
1. 각 이미지마다 해상도 점수 계산 (다름: 0.5, 1.0, 1.0)
2. 각 이미지마다 선명도 계산 (비슷할 수 있음)
3. 각 이미지마다 노이즈 계산 (비슷할 수 있음)
4. ImageHash로 중복 감지 (해시가 비슷하면 중복으로 판정)
5. 중복도 점수 반영

**효율성**:
- ⚠️ 해상도만 다른 동일 이미지도 모든 지표를 다시 계산
- ✅ 중복도는 감지 가능 (ImageHash가 리사이즈에 어느 정도 강건)

**개선 가능**:
- 중복 이미지 감지 후 일부 지표만 계산하거나
- 중복 이미지 그룹 중 대표 이미지만 선택하여 계산

## 📝 요약

| 구분 | 현재 방식 | 개선 가능 |
|------|----------|----------|
| **이미지 분석** | 모든 이미지 동일 알고리즘 | 타입별 맞춤 알고리즘 |
| **텍스트 분석** | 기본 패턴 검사 | 실제 맞춤법 API 연동 |
| **중복 처리** | 모든 지표 계산 후 중복 감지 | 중복 감지 후 선택적 계산 |
| **범용성** | ✅ 높음 | ⚠️ 타입별로 달라짐 |
| **정확도** | ⚠️ 보통 | ✅ 타입별로 향상 가능 |
| **처리 속도** | ✅ 빠름 | ⚠️ 타입 감지로 느려짐 |

**결론**: 현재는 모든 이미지/텍스트에 **동일한 표준 알고리즘**을 사용하고 있으며, 모든 지표를 항상 계산합니다. 해상도만 다른 동일 이미지도 각각 계산하지만, 중복도로 감지는 가능합니다. 필요시 중복 감지 후 효율적인 계산 방식으로 개선할 수 있습니다.

