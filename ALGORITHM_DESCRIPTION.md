# 품질 진단 알고리즘 설명서

현재 프로그램에서 사용하는 품질 진단 알고리즘에 대한 상세 설명입니다.

## 📊 현재 상황

**답변: 모든 이미지/텍스트에 동일한 알고리즘을 사용합니다.**

이미지 타입(사진, 그래픽, 다이어그램 등)에 따라 다른 알고리즘을 적용하지 않고, **표준화된 지표**를 사용하여 일관된 평가를 제공합니다.

---

## 🖼️ 이미지 품질 진단 알고리즘

### 현재 사용 중인 알고리즘 (모든 이미지 공통)

#### 1. **해상도 점수 (Resolution Score)**

**알고리즘**: 크기 기반 점수 계산
```python
기준: 최소 512x512 픽셀
- 512x512 이상: 1.0점
- 512 미만: 비례 점수 (예: 256x256 = 0.5점)
- 종횡비 4:1 초과 시 패널티 (-10%)
- 2048픽셀 이상 시 보너스 (+10%)
```

**적용 방식**: 모든 이미지에 동일 적용
- 자연사진, 그래픽, 스크린샷 모두 동일 기준

---

#### 2. **선명도 점수 (Sharpness Score)**

**알고리즘**: **Laplacian Variance 방법**

```python
1. 이미지를 Grayscale로 변환
2. Laplacian 필터 적용 (엣지 감지)
3. 분산(Variance) 계산
4. 분산값을 0-1 점수로 변환:
   - 0-100: 매우 흐림 (0.0-0.4점)
   - 100-500: 보통 (0.4-0.7점)
   - 500-1000: 선명 (0.7-1.0점)
   - 1000+: 매우 선명 (1.0점)
```

**특징**:
- ✅ **범용 알고리즘**: 사진, 그래픽, 텍스트 이미지 모두 적용 가능
- ✅ **표준 방법**: 컴퓨터 비전에서 널리 사용되는 방법
- ⚠️ **제한**: 매우 특수한 이미지(예: 의도적으로 흐린 예술 작품)는 부정확할 수 있음

---

#### 3. **노이즈 점수 (Noise Score)**

**알고리즘**: **Gaussian Blur 차이 분석**

```python
1. 원본 이미지에 Gaussian Blur (5x5 커널) 적용
2. 원본과 블러 이미지의 절대 차이 계산
3. 차이의 평균값으로 노이즈 수준 측정
4. 노이즈 수준을 점수로 변환:
   - 0-10: 매우 깨끗 (1.0점)
   - 10-30: 양호 (0.8-1.0점)
   - 30-50: 보통 (0.6-0.8점)
   - 50+: 노이즈 많음 (0.3-0.6점)
```

**특징**:
- ✅ **전역 노이즈 감지**: 이미지 전체의 노이즈 측정
- ⚠️ **제한**: 텍스처가 많은 이미지(예: 나무, 벽돌)는 노이즈로 오인될 수 있음

---

#### 4. **중복도 점수 (Duplication Score)**

**알고리즘**: **ImageHash (Average Hash)**

```python
단일 이미지 분석 시:
- 항상 1.0 (중복 없음)

여러 이미지 배치 분석 시:
1. 각 이미지의 Average Hash 계산
2. 모든 이미지 쌍의 해시 차이 계산
3. 차이 ≤ 5인 경우 중복으로 판정
4. 중복 비율 계산 후 1에서 빼서 점수화
```

**특징**:
- ✅ **빠른 중복 감지**: 해시 기반으로 빠름
- ⚠️ **제한**: 시각적으로 다르지만 해시가 비슷한 경우 오판 가능

---

## 📄 텍스트 품질 진단 알고리즘

### 현재 사용 중인 알고리즘 (모든 텍스트 공통)

#### 1. **정확성 점수 (Accuracy Score)**

**알고리즘**: **패턴 기반 오류 검사**

```python
1. 정규표현식으로 오류 패턴 찾기:
   - 연속된 공백 (예: "   ")
   - 한글-영문 불규칙 혼용
   
2. 한글 비율 체크:
   - 한국어 텍스트 가정
   - 한글 비율 < 30% 시 패널티

3. 오류 비율 계산:
   오류 비율 = (오류 개수) / (총 단어 수)
   정확성 = 1.0 - 오류 비율
```

**특징**:
- ⚠️ **기본 수준**: 실제 맞춤법 검사(hanspell API)는 미사용
- ✅ **빠른 처리**: 패턴 기반으로 즉시 처리
- 📝 **개선 가능**: 실제 맞춤법 검사 API 연결 가능

---

#### 2. **중복도 점수 (Duplication Score)**

**알고리즘**: **Sentence Transformer (의미 기반 유사도)**

```python
1. 문장 단위로 분리
2. SentenceTransformer 모델로 각 문장 임베딩 생성
   - 모델: paraphrase-multilingual-MiniLM-L12-v2
   - 다국어 지원 (한국어 포함)
   
3. 모든 문장 쌍의 코사인 유사도 계산
4. 평균 유사도를 중복도로 사용:
   중복도 점수 = 1.0 - 평균 유사도
```

**특징**:
- ✅ **의미 기반**: 단어가 다르지만 의미가 같으면 감지
- ✅ **다국어 지원**: 한국어, 영어 모두 처리
- ⚠️ **모델 로드 필요**: 첫 실행 시 시간 소요 (약 200MB)

---

#### 3. **완전성 점수 (Completeness Score)**

**알고리즘**: **문장 길이 기반 검사**

```python
1. 모든 문장 추출
2. 최소 길이 기준 (10자) 적용
3. 의미 있는 문장 비율 계산:
   완전성 = (길이 ≥ 10자 문장 수) / (전체 문장 수)
```

**특징**:
- ✅ **간단 명확**: 구현이 쉽고 빠름
- ⚠️ **제한**: 의미가 아니라 길이만 확인

---

## 🔄 이미지 타입별 다른 알고리즘 사용 여부

### 현재: ❌ **동일 알고리즘 사용**

모든 이미지에 대해:
- 사진
- 그래픽
- 다이어그램
- 스크린샷
- 텍스트가 포함된 이미지

→ **동일한 4가지 지표 (해상도, 선명도, 노이즈, 중복도) 적용**

---

## 💡 타입별 다른 알고리즘을 사용하려면?

### 예시: 이미지 타입별 커스터마이징

```python
def analyze_image_quality_by_type(img, image_type="auto"):
    """
    이미지 타입에 따라 다른 알고리즘 적용
    """
    if image_type == "photo":
        # 자연 사진: 선명도와 노이즈에 더 집중
        return analyze_for_photo(img)
    
    elif image_type == "graphic":
        # 그래픽: 해상도와 색상 일관성에 집중
        return analyze_for_graphic(img)
    
    elif image_type == "diagram":
        # 다이어그램: 텍스트 가독성과 선 명확성에 집중
        return analyze_for_diagram(img)
    
    else:
        # 기본 알고리즘 (현재 방식)
        return analyze_image_quality(img)
```

### 타입 자동 감지 방법

1. **이미지 분류 모델 사용** (예: ResNet, EfficientNet)
2. **메타데이터 분석** (파일명, EXIF 정보)
3. **이미지 특성 분석** (색상 분포, 엣지 밀도 등)

---

## 📈 현재 알고리즘의 장단점

### ✅ 장점

1. **일관성**: 모든 데이터에 동일한 기준 적용
2. **간단함**: 구현이 간단하고 이해하기 쉬움
3. **빠름**: 표준 알고리즘으로 처리 속도 빠름
4. **범용성**: 다양한 이미지 타입에 적용 가능

### ⚠️ 단점

1. **타입별 특성 미고려**: 사진과 그래픽의 품질 기준이 다를 수 있음
2. **도메인 특화 부족**: 의료 이미지, 위성 이미지 등 특수 분야에 부적합
3. **주관적 품질 반영 어려움**: 예술적 의도가 있는 이미지 평가 어려움

---

## 🚀 개선 제안

### 1. 이미지 타입 자동 감지 추가

```python
# 이미지 분류 모델로 타입 감지
image_type = detect_image_type(img)  # "photo", "graphic", "diagram"
scores = analyze_image_quality_by_type(img, image_type)
```

### 2. 도메인별 맞춤 지표 추가

```python
# 의료 이미지: 대비, 명암비 추가
# 위성 이미지: 해상도 기준 더 엄격
# 자연 사진: 노이즈 감지 개선
```

### 3. 실제 맞춤법 검사 API 연동

```python
# hanspell 또는 한국어 맞춤법 검사 API 사용
accuracy = check_spelling_with_api(text)
```

---

## 📝 요약

| 구분 | 현재 방식 | 개선 가능 |
|------|----------|----------|
| **이미지 분석** | 모든 이미지 동일 알고리즘 | 타입별 맞춤 알고리즘 |
| **텍스트 분석** | 기본 패턴 검사 | 실제 맞춤법 API 연동 |
| **범용성** | ✅ 높음 | ⚠️ 타입별로 달라짐 |
| **정확도** | ⚠️ 보통 | ✅ 타입별로 향상 가능 |
| **처리 속도** | ✅ 빠름 | ⚠️ 타입 감지로 느려짐 |

**결론**: 현재는 모든 이미지/텍스트에 **동일한 표준 알고리즘**을 사용하고 있으며, 이는 범용성과 일관성을 위해 적절한 선택입니다. 필요시 타입별 맞춤 알고리즘을 추가할 수 있습니다.

