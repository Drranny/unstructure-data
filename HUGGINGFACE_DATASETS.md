# Hugging Face 데이터셋 사용 가이드

Hugging Face Hub에서 제공하는 수천 개의 이미지/텍스트 데이터셋을 자동으로 다운로드하여 분석할 수 있습니다.

## 사용 방법

### 방법 1: 미리 준비된 데이터셋 선택

앱의 "데이터셋 배치 분석" 탭에서:

1. 데이터 타입 선택 (이미지 / 텍스트)
2. 데이터셋 소스: "미리 탑재된 샘플 데이터셋" 선택
3. 데이터셋 선택:
   - **이미지**: beans, food101, cifar10
   - **텍스트**: imdb, yelp_review_full, ag_news
4. 다운로드 방식 선택 (샘플 개수 / 퍼센티지 / 전체)
5. 분석 시작

### 방법 2: Hugging Face에서 검색

1. 데이터셋 소스: "Hugging Face에서 검색" 선택
2. **인기 데이터셋 목록** 확인 (좌측 열)
3. 또는 **검색어 입력** (우측 열)
4. 검색 결과에서 데이터셋 ID 확인
5. "분석할 데이터셋 ID 입력" 필드에 ID 입력
6. 다운로드 방식 선택 및 분석 시작

### 다운로드 옵션

- **샘플 개수 지정**: 10~500개 슬라이더로 선택
- **전체 데이터셋 퍼센티지**: 1~100% 슬라이더로 선택
- **전체 다운로드**: 전체 데이터셋 다운로드

**참고**: Streaming 모드로 필요한 데이터만 다운로드하여 메모리 효율적입니다.

---

## 인기 데이터셋 목록

### 이미지 데이터셋

| 데이터셋 이름 | 이미지 수 | 용도 | 추천도 |
|-------------|----------|------|--------|
| `beans` | ~1,363 | 콩 질병 분류 | ⭐⭐⭐ 빠른 테스트에 적합 |
| `food101` | 101,000 | 음식 이미지 분류 | ⭐⭐ 시간 소요 |
| `cifar10` | 50,000 | 객체 분류 | ⭐⭐ 중간 크기 |
| `cifar100` | 50,000 | 객체 분류 (100 클래스) | ⭐⭐ |
| `mnist` | 70,000 | 손글씨 숫자 (Grayscale) | ⭐⭐ |
| `fashion_mnist` | 70,000 | 패션 아이템 | ⭐⭐ |
| `cats_vs_dogs` | ~23,000 | 고양이 vs 개 분류 | ⭐⭐ |
| `imagenet-1k` | 1,281,167 | 객체 분류 | ⚠️ 매우 큼 |

### 텍스트 데이터셋

| 데이터셋 이름 | 설명 | 추천도 |
|-------------|------|--------|
| `imdb` | 영화 리뷰 (감정 분석) | ⭐⭐⭐ |
| `yelp_review_full` | Yelp 리뷰 (5점 척도) | ⭐⭐⭐ |
| `ag_news` | 뉴스 기사 분류 | ⭐⭐⭐ |
| `squad` | 질문-답변 | ⭐⭐ |
| `glue` | 다양한 NLP 작업 | ⭐⭐ |

---

## 앱 내 검색 기능

앱에서 직접 Hugging Face 데이터셋을 검색할 수 있습니다:

1. "Hugging Face에서 검색" 선택
2. 좌측 열: 인기 데이터셋 목록 자동 표시
3. 우측 열: 검색어 입력하여 검색
4. 검색 결과에서 데이터셋 ID 확인 후 입력

### 검색 기능 개선 사항

- ✅ **정확한 데이터셋 ID 검색**: `사용자명/데이터셋명` 형식으로 정확한 ID를 입력하면 바로 조회됩니다
  - 예: `hcaoaf/MoleculeQA`, `imdb`, `beans`
- ✅ **넓은 검색 범위**: 모든 텍스트/이미지 데이터셋 검색 가능 (task 필터 완화)
  - 텍스트 분류뿐만 아니라 질문-답변, 자연어 추론 등 모든 텍스트 관련 데이터셋 검색
- ✅ **자동 재시도**: API 실패 시 최대 3회 자동 재시도
- ✅ **검색 결과 안내**: 결과가 없을 때 명확한 안내 메시지 표시

### 웹에서 검색

Hugging Face Hub에서 직접 검색:
1. https://huggingface.co/datasets 접속
2. "Task" 필터에서 작업 타입 선택
3. 데이터셋 선택 후 이름 복사
4. 앱의 "분석할 데이터셋 ID 입력"에 붙여넣기

---

## 사용 팁

### 처음 테스트할 때

- 작은 데이터셋부터 시작: `beans` (이미지) 또는 `imdb` (텍스트)
- 샘플 개수 10-20개로 시작
- 퍼센티지 다운로드 사용 (예: 10%)로 메모리 절약

### 큰 데이터셋 사용 시

- 샘플 개수 제한 (10-100개 권장)
- 퍼센티지 다운로드 활용 (1~50%)
- 첫 다운로드 시 시간 소요 (인내심 필요)
- 이후 캐시된 데이터 사용으로 빠름

### 데이터셋 ID 입력 형식

일반적인 형식:
```
데이터셋이름
```
예: `beans`, `food101`, `imdb`

네임스페이스 포함 (필요한 경우):
```
사용자명/데이터셋이름
```
예: `hcaoaf/MoleculeQA`, `username/dataset-name`

**주의**: 네임스페이스가 있는 데이터셋은 반드시 전체 경로를 입력해야 합니다. 정확한 형식으로 입력하면 자동으로 해당 데이터셋을 찾아줍니다.

---

## 문제 해결

### "데이터셋을 찾을 수 없습니다" 오류

**원인**: 데이터셋 이름 오타 또는 존재하지 않는 데이터셋

**해결책**:
1. Hugging Face Hub에서 정확한 이름 확인 (https://huggingface.co/datasets)
2. 대소문자 구분 주의
3. 네임스페이스 포함 여부 확인

### "이미지/텍스트 컬럼을 찾을 수 없습니다" 오류

**원인**: 데이터셋 구조가 예상과 다름

**해결책**:
- 프로그램이 자동으로 이미지/텍스트 컬럼을 감지하지만, 일부 데이터셋은 실패할 수 있음
- 다른 유사한 데이터셋 사용
- 커스텀 폴더 옵션으로 대체

### 다운로드가 너무 느림

**해결책**:
1. 샘플 개수 줄이기 (10-50개)
2. 퍼센티지 다운로드 사용 (10-20%)
3. 작은 데이터셋 선택 (`beans`, `imdb` 등)
4. 네트워크 연결 확인
5. Streaming 모드가 자동으로 사용되어 필요한 데이터만 다운로드

### 메모리 부족 오류

**해결책**:
- 퍼센티지 다운로드 사용 (전체 대신 일부만)
- 샘플 개수 줄이기
- 더 작은 데이터셋 선택

---

## 데이터셋 소스 비교

| 데이터셋 소스 | 다운로드 방식 | 자동 다운로드 | 텍스트 지원 | 추천 용도 |
|-------------|------------|------------|----------|----------|
| **CIFAR-10** | torchvision | ✅ 자동 | ❌ | 빠른 이미지 테스트 |
| **Hugging Face** | datasets 라이브러리 | ✅ 자동 | ✅ | 다양한 데이터셋 (이미지/텍스트) |
| **커스텀 폴더** | 로컬 파일 | - | ✅ | 본인 데이터 |

## 추천 워크플로우

1. **첫 테스트**: 
   - 이미지: `beans` 데이터셋 (10-20개 샘플)
   - 텍스트: `imdb` 데이터셋 (10-20개 샘플)

2. **빠른 테스트**: 
   - CIFAR-10 또는 Hugging Face cifar10 (50개 샘플)

3. **다양한 데이터**: 
   - Hugging Face 검색 기능 활용
   - 인기 목록에서 선택

4. **본인 데이터**: 
   - 커스텀 폴더 옵션 사용

## 주요 특징

- ✅ **자동 다운로드**: 데이터셋 이름만 입력하면 자동으로 다운로드
- ✅ **Streaming 모드**: 필요한 데이터만 다운로드하여 메모리 효율적
- ✅ **퍼센티지 다운로드**: 전체 대신 일부만 다운로드 가능
- ✅ **검색 기능**: 앱 내에서 데이터셋 검색 및 선택
- ✅ **다양한 데이터셋**: 수천 개의 이미지/텍스트 데이터셋 지원
- ✅ **즉시 사용**: CIFAR-10처럼 간단하게 사용 가능

## 요약

Hugging Face 데이터셋은 수동 다운로드 없이 즉시 사용할 수 있습니다. 앱에서 검색하거나 미리 준비된 목록에서 선택하여 바로 분석을 시작할 수 있습니다.

---

## 기술적 구현 (개발자용)

### Hugging Face 연결 방법

이 프로그램은 두 가지 라이브러리를 사용하여 Hugging Face에 연결합니다:

#### 1. `datasets` 라이브러리 (데이터셋 로드)

```python
from datasets import load_dataset

# 이미지 데이터셋 로드
dataset = load_dataset("beans", split="train")

# 텍스트 데이터셋 로드
dataset = load_dataset("imdb", split="train")

# Streaming 모드 (메모리 효율적)
dataset = load_dataset("food101", split="train", streaming=True)
```

**특징**:
- 공식 Hugging Face 라이브러리
- 수천 개의 데이터셋 자동 다운로드
- Streaming 모드로 부분 다운로드 가능
- 자동 캐싱 및 관리

#### 2. `huggingface_hub` 라이브러리 (검색 및 목록 조회)

```python
from huggingface_hub import HfApi

api = HfApi()

# 데이터셋 검색
datasets = api.list_datasets(
    search="image classification",
    task="image-classification",
    limit=50
)

# 인기 데이터셋 목록
datasets = api.list_datasets(
    sort="downloads",
    direction=-1,
    limit=30
)
```

**특징**:
- Hugging Face Hub API 클라이언트
- 데이터셋 검색 및 필터링
- 메타데이터 조회 (다운로드 수, 좋아요 등)

### 이 기능이 널리 사용되는 이유

#### 1. **표준 방식**
- Hugging Face는 AI/ML 커뮤니티에서 사실상의 표준
- 거의 모든 최신 프로젝트에서 사용
- PyTorch, TensorFlow, JAX 등과 호환

#### 2. **수많은 데이터셋**
- 수만 개의 공개 데이터셋
- 이미지, 텍스트, 오디오, 비디오 등 다양한 형식
- 주기적으로 새로운 데이터셋 추가

#### 3. **편리함**
```python
# 단 한 줄로 데이터셋 로드
dataset = load_dataset("imagenet-1k")

# vs 기존 방식 (수동 다운로드 + 압축 해제 + 전처리)
# wget, tar, unzip, csv 읽기, 이미지 변환 등...
```

#### 4. **메모리 효율적**
- Streaming 모드: 필요한 데이터만 메모리에 로드
- 자동 캐싱: 한 번 다운로드하면 재사용
- 대용량 데이터셋도 처리 가능

### 다른 프로젝트에서의 활용 예시

#### PyTorch/TensorFlow 학습
```python
from datasets import load_dataset

# 데이터셋 로드
train_data = load_dataset("imagenet-1k", split="train")

# PyTorch DataLoader로 변환
from torch.utils.data import DataLoader
loader = DataLoader(train_data, batch_size=32)
```

#### Jupyter Notebook 분석
```python
# 데이터 탐색
dataset = load_dataset("food101")
print(dataset["train"][0])  # 첫 번째 샘플 확인
```

#### 대규모 프로젝트
- OpenAI, Google, Meta 등의 연구 프로젝트
- Kaggle 대회 데이터셋
- 학술 논문의 벤치마크 데이터셋

### 이 프로그램의 구현 흐름

1. **사용자 입력**: 데이터셋 이름 또는 검색어
2. **검색 (선택사항)**: `huggingface_hub.HfApi`로 데이터셋 찾기
3. **로드**: `datasets.load_dataset()`으로 데이터 다운로드
4. **처리**: 이미지/텍스트를 PIL Image 또는 문자열로 변환
5. **분석**: 품질 진단 알고리즘 적용

### 주요 장점

✅ **표준 라이브러리**: 업계 표준 사용  
✅ **간단한 구현**: 몇 줄의 코드로 완성  
✅ **확장성**: 새로운 데이터셋 추가 자동 지원  
✅ **메모리 효율**: Streaming 모드로 대용량 처리 가능  
✅ **유지보수**: Hugging Face가 관리하므로 자동 업데이트  

