"""ë¼ë²¨ë§ ê¸°ë°˜ í‰ê°€ íƒ­"""
import streamlit as st
import pandas as pd
import json
from src.quality_evaluator import (
    evaluate_semantic_accuracy, evaluate_consistency,
    evaluate_completeness, evaluate_validity,
    evaluate_diversity, evaluate_safety,
    evaluate_quality_with_thresholds
)
from src.utils import load_quality_thresholds


def render_tab3(tab):
    st.header("ë¼ë²¨ë§ ê¸°ë°˜ í’ˆì§ˆ í‰ê°€")
    st.markdown("""
    **ë¼ë²¨ë§ ì •ë³´ê°€ í¬í•¨ëœ ë°ì´í„°ì…‹ì˜ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.**
    ì´ ëª¨ë“œëŠ” ë‹¤ìŒ ì§€í‘œë¥¼ í‰ê°€í•©ë‹ˆë‹¤:
    - **ì •í™•ì„±**: mAP, IOU, F1-Score (ë¼ë²¨ë§ ì •í™•ì„±)
    - **ì¼ê´€ì„±**: Cohen's Kappa, IRR (í‰ê°€ì ê°„ ì¼ê´€ì„±)
    - **ì™„ì „ì„±**: MissingRate, NullRate (ë°ì´í„° êµ¬ì¡°)
    - **ìœ íš¨ì„±**: ROUGE, BLEU, CER (ëª¨ë¸ ì„±ëŠ¥)
    - **ë‹¤ì–‘ì„±**: CategoryVariance, Entropy (ë°ì´í„° ë¶„í¬)
    - **ì•ˆì „ì„±**: ToxicityRate (ìœ í•´ í‘œí˜„ ê²€ì¶œ)
    """)
    # í‰ê°€ ëª¨ë“œ ì„ íƒ
    evaluation_mode = st.radio(
        "í‰ê°€ ëª¨ë“œ ì„ íƒ",
        ["ê°„ë‹¨ í‰ê°€ (CSV/JSON)", "ê³ ê¸‰ í‰ê°€ (í‰ê°€ì ì •ë³´ í¬í•¨)"],
        horizontal=True,
        help="ê°„ë‹¨ í‰ê°€: ì˜ˆì¸¡ ë¼ë²¨ê³¼ ì‹¤ì œ ë¼ë²¨ë§Œ í•„ìš”. ê³ ê¸‰ í‰ê°€: ì—¬ëŸ¬ í‰ê°€ìì˜ ë¼ë²¨ ì •ë³´ í•„ìš”."
    )
    if evaluation_mode == "ê°„ë‹¨ í‰ê°€ (CSV/JSON)":
        st.subheader("ë°ì´í„°ì…‹ ì—…ë¡œë“œ")
        # ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš© ì˜µì…˜
        use_sample_data = False
        if 'sample_labeling_data' in st.session_state:
            col_sample, col_upload = st.columns([1, 2])
            with col_sample:
                if st.button("ğŸ“Š ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©", use_container_width=True, type="secondary"):
                    use_sample_data = True
                    st.session_state['use_sample_labeling_data'] = True
                    st.rerun()
            with col_upload:
                st.caption("ë˜ëŠ” íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
        col1, col2 = st.columns(2)
        with col1:
            dataset_file = st.file_uploader(
                "ë°ì´í„°ì…‹ íŒŒì¼ (CSV/JSON)",
                type=["csv", "json"],
                help="ì˜ˆì¸¡ ë¼ë²¨ê³¼ ì‹¤ì œ ë¼ë²¨ì´ í¬í•¨ëœ íŒŒì¼"
            )
        with col2:
            task_type = st.selectbox(
                "ì‘ì—… íƒ€ì…",
                ["classification", "detection", "generation", "qa"],
                help="ë°ì´í„°ì…‹ì˜ ì‘ì—… íƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”"
            )
        # ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        if 'use_sample_labeling_data' in st.session_state and st.session_state.get('use_sample_labeling_data', False):
            if 'sample_labeling_data' in st.session_state:
                sample_data = st.session_state['sample_labeling_data']
                df = sample_data['dataframe']
                task_type = sample_data['task_type']
                prediction_col = sample_data['prediction_col']
                ground_truth_col = sample_data['ground_truth_col']
                st.success(f"âœ… ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš© ì¤‘: {len(df)}ê°œ í•­ëª© ({task_type} ì‘ì—…)")
                st.info("ğŸ’¡ ì‚¬ì´ë“œë°”ì—ì„œ ë‹¤ë¥¸ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                # ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                with st.expander("ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=True):
                    st.dataframe(df.head(10), use_container_width=True)
                # ìë™ìœ¼ë¡œ í‰ê°€ ì‹¤í–‰
                with st.spinner("í’ˆì§ˆì„ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        from src.quality_evaluator import (
                            evaluate_semantic_accuracy,
                            evaluate_completeness,
                            evaluate_validity,
                            evaluate_diversity,
                            evaluate_safety,
                            evaluate_quality_with_thresholds
                        )
                        from src.utils import load_quality_thresholds
                        predictions = df[prediction_col].tolist()
                        ground_truth = df[ground_truth_col].tolist()
                        # ë°ì´í„° íƒ€ì… ê²€ì¦
                        if len(predictions) != len(ground_truth):
                            st.error("âš ï¸ ì˜ˆì¸¡ ë¼ë²¨ê³¼ ì‹¤ì œ ë¼ë²¨ì˜ ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                        elif len(predictions) == 0:
                            st.error("âš ï¸ í‰ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            # í’ˆì§ˆ í‰ê°€ ì‹¤í–‰
                            quality_results = {}
                            # 1. ì •í™•ì„± í‰ê°€
                            accuracy_results = evaluate_semantic_accuracy(
                                predictions, ground_truth, task_type=task_type
                            )
                            quality_results["semantic_accuracy"] = accuracy_results
                            # 2. ì™„ì „ì„± í‰ê°€
                            required_fields = [prediction_col, ground_truth_col]
                            completeness_results = evaluate_completeness(
                                df.to_dict('records'), required_fields
                            )
                            quality_results["completeness"] = completeness_results
                            # 3. ìœ íš¨ì„± í‰ê°€ (í…ìŠ¤íŠ¸ ì‘ì—…ì¸ ê²½ìš°)
                            if task_type in ["generation", "qa"]:
                                validity_results = evaluate_validity(
                                    [str(p) for p in predictions],
                                    [str(g) for g in ground_truth],
                                    task_type=task_type
                                )
                                quality_results["validity"] = validity_results
                            # 4. ë‹¤ì–‘ì„± í‰ê°€
                            diversity_results = evaluate_diversity(ground_truth)
                            quality_results["diversity"] = diversity_results
                            # 5. ì•ˆì „ì„± í‰ê°€ (í…ìŠ¤íŠ¸ì¸ ê²½ìš°)
                            if task_type in ["generation", "qa", "classification"]:
                                safety_results = evaluate_safety([str(g) for g in ground_truth])
                                quality_results["safety"] = safety_results
                            # ì„ê³„ê°’ ê¸°ë°˜ í‰ê°€
                            thresholds = load_quality_thresholds()
                            evaluated_results = evaluate_quality_with_thresholds(
                                quality_results, thresholds
                            )
                            # ê²°ê³¼ ì €ì¥
                            st.session_state['labeling_evaluation'] = {
                                'results': evaluated_results,
                                'raw_results': quality_results,
                                'dataset_name': 'ìƒ˜í”Œ ë°ì´í„°'
                            }
                            # ê²°ê³¼ í‘œì‹œ
                            st.success("í‰ê°€ ì™„ë£Œ!")
                            st.session_state['use_sample_labeling_data'] = False  # í‰ê°€ í›„ í”Œë˜ê·¸ ë¦¬ì…‹
                    except Exception as e:
                        st.error(f"âš ï¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        st.exception(e)
        elif dataset_file is not None:
            try:
                import pandas as pd
                import json
                # íŒŒì¼ ì½ê¸° (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)
                try:
                    if dataset_file.name.endswith('.csv'):
                        df = pd.read_csv(dataset_file, encoding='utf-8')
                        st.success(f"CSV íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í•­ëª©")
                    elif dataset_file.name.endswith('.json'):
                        dataset_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                        data = json.load(dataset_file)
                        if isinstance(data, list):
                            df = pd.DataFrame(data)
                        else:
                            df = pd.DataFrame([data])
                        st.success(f"JSON íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í•­ëª©")
                    else:
                        st.error("âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. CSV ë˜ëŠ” JSON íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                        df = None
                except UnicodeDecodeError:
                    st.error("âš ï¸ íŒŒì¼ ì¸ì½”ë”© ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. UTF-8 ì¸ì½”ë”© íŒŒì¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
                    df = None
                except json.JSONDecodeError as e:
                    st.error(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                    df = None
                except Exception as e:
                    st.error(f"âš ï¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                    df = None
                # ì»¬ëŸ¼ ì„ íƒ (ë°ì´í„°í”„ë ˆì„ì´ ë¡œë“œëœ ê²½ìš°ì—ë§Œ)
                if df is not None and not df.empty:
                    st.subheader("ì»¬ëŸ¼ ë§¤í•‘")
                    col1, col2 = st.columns(2)
                    with col1:
                        prediction_col = st.selectbox(
                            "ì˜ˆì¸¡ ë¼ë²¨ ì»¬ëŸ¼",
                            df.columns.tolist(),
                            help="ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë¼ë²¨ ì»¬ëŸ¼ ì„ íƒ"
                        )
                    with col2:
                        ground_truth_col = st.selectbox(
                            "ì‹¤ì œ ë¼ë²¨ ì»¬ëŸ¼",
                            df.columns.tolist(),
                            help="ì‹¤ì œ ì •ë‹µ ë¼ë²¨ ì»¬ëŸ¼ ì„ íƒ"
                        )
                    # ì»¬ëŸ¼ ê²€ì¦
                    if prediction_col == ground_truth_col:
                        st.warning("âš ï¸ ì˜ˆì¸¡ ë¼ë²¨ê³¼ ì‹¤ì œ ë¼ë²¨ ì»¬ëŸ¼ì´ ë™ì¼í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì»¬ëŸ¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                    with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
                        try:
                            st.dataframe(df[[prediction_col, ground_truth_col]].head(10))
                        except KeyError as e:
                            st.error(f"âš ï¸ ì»¬ëŸ¼ ì˜¤ë¥˜: {e}")
                else:
                    st.warning("âš ï¸ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                # í‰ê°€ ì‹¤í–‰ (ë°ì´í„°í”„ë ˆì„ê³¼ ì»¬ëŸ¼ ê²€ì¦ í›„)
                if df is not None and not df.empty:
                    # prediction_colê³¼ ground_truth_colì´ ì •ì˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    if 'prediction_col' in locals() and 'ground_truth_col' in locals():
                        if prediction_col in df.columns and ground_truth_col in df.columns:
                            if st.button("í’ˆì§ˆ í‰ê°€ ì‹œì‘", type="primary", use_container_width=True):
                                with st.spinner("í’ˆì§ˆì„ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
                                    try:
                                        from src.quality_evaluator import (
                                            evaluate_semantic_accuracy,
                                            evaluate_completeness,
                                            evaluate_validity,
                                            evaluate_diversity,
                                            evaluate_safety,
                                            evaluate_quality_with_thresholds
                                        )
                                        from src.utils import load_quality_thresholds
                                        predictions = df[prediction_col].tolist()
                                        ground_truth = df[ground_truth_col].tolist()
                                        # ë°ì´í„° íƒ€ì… ê²€ì¦
                                        if len(predictions) != len(ground_truth):
                                            st.error("âš ï¸ ì˜ˆì¸¡ ë¼ë²¨ê³¼ ì‹¤ì œ ë¼ë²¨ì˜ ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                                        elif len(predictions) == 0:
                                            st.error("âš ï¸ í‰ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                        else:
                                            # í’ˆì§ˆ í‰ê°€ ì‹¤í–‰
                                            quality_results = {}
                                            # 1. ì •í™•ì„± í‰ê°€
                                            accuracy_results = evaluate_semantic_accuracy(
                                                predictions, ground_truth, task_type=task_type
                                            )
                                            quality_results["semantic_accuracy"] = accuracy_results
                                            # 2. ì™„ì „ì„± í‰ê°€
                                            required_fields = [prediction_col, ground_truth_col]
                                            completeness_results = evaluate_completeness(
                                                df.to_dict('records'), required_fields
                                            )
                                            quality_results["completeness"] = completeness_results
                                            # 3. ìœ íš¨ì„± í‰ê°€ (í…ìŠ¤íŠ¸ ì‘ì—…ì¸ ê²½ìš°)
                                            if task_type in ["generation", "qa"]:
                                                validity_results = evaluate_validity(
                                                    [str(p) for p in predictions],
                                                    [str(g) for g in ground_truth],
                                                    task_type=task_type
                                                )
                                                quality_results["validity"] = validity_results
                                            # 4. ë‹¤ì–‘ì„± í‰ê°€
                                            diversity_results = evaluate_diversity(ground_truth)
                                            quality_results["diversity"] = diversity_results
                                            # 5. ì•ˆì „ì„± í‰ê°€ (í…ìŠ¤íŠ¸ì¸ ê²½ìš°)
                                            if task_type in ["generation", "qa", "classification"]:
                                                safety_results = evaluate_safety([str(g) for g in ground_truth])
                                                quality_results["safety"] = safety_results
                                            # ì„ê³„ê°’ ê¸°ë°˜ í‰ê°€
                                            thresholds = load_quality_thresholds()
                                            evaluated_results = evaluate_quality_with_thresholds(
                                                quality_results, thresholds
                                            )
                                            # ê²°ê³¼ ì €ì¥
                                            st.session_state['labeling_evaluation'] = {
                                                'results': evaluated_results,
                                                'raw_results': quality_results,
                                                'dataset_name': dataset_file.name
                                            }
                                            # ê²°ê³¼ í‘œì‹œ
                                            st.success("í‰ê°€ ì™„ë£Œ!")
                                    except Exception as e:
                                        st.error(f"âš ï¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                                        st.exception(e)
            except Exception as e:
                st.error(f"âš ï¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.exception(e)
        # ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš© í›„ ê²°ê³¼ í‘œì‹œë„ í¬í•¨
        # ê²°ê³¼ í‘œì‹œ (í‰ê°€ê°€ ì„±ê³µí•œ ê²½ìš°)
        if 'labeling_evaluation' in st.session_state:
            evaluated_results = st.session_state['labeling_evaluation']['results']
            st.divider()
            # ê²°ê³¼ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ í‘œì‹œ
            for category, metrics in evaluated_results.items():
                st.subheader(f"ğŸ“Š {category.replace('_', ' ').title()}")
                # ë©”íŠ¸ë¦­ë³„ í‘œì‹œ
                metric_data = []
                for metric_name, metric_info in metrics.items():
                    if isinstance(metric_info, dict) and "value" in metric_info:
                        value = metric_info.get("value")
                        threshold = metric_info.get("threshold")
                        status = metric_info.get("status", "N/A")
                        metric_display = metric_info.get("metric_display", metric_name)
                        if value is not None:
                            metric_data.append({
                                "ì§€í‘œ": metric_display,
                                "ê°’": f"{value:.3f}" if isinstance(value, (int, float)) else str(value),
                                "ì„ê³„ê°’": f"{threshold:.3f}" if threshold is not None else "N/A",
                                "ìƒíƒœ": status
                            })
                if metric_data:
                    import pandas as pd
                    df_metrics = pd.DataFrame(metric_data)
                    st.dataframe(df_metrics, use_container_width=True)
                    # í†µê³„ ìš”ì•½
                    pass_count = sum(1 for m in metric_data if "âœ…" in m["ìƒíƒœ"])
                    total_count = len(metric_data)
                    st.metric("í†µê³¼ ì§€í‘œ", f"{pass_count}/{total_count}")
                else:
                    st.info("ê³„ì‚° ê°€ëŠ¥í•œ ì§€í‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.divider()
    else:  # ê³ ê¸‰ í‰ê°€
        st.subheader("ê³ ê¸‰ í‰ê°€ (í‰ê°€ì ì •ë³´ í¬í•¨)")
        st.info("""
        **ê³ ê¸‰ í‰ê°€ ëª¨ë“œ**ëŠ” ì—¬ëŸ¬ í‰ê°€ìì˜ ë¼ë²¨ë§ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.
        í•„ìš” ì •ë³´:
        - ì—¬ëŸ¬ í‰ê°€ìì˜ ë¼ë²¨ íŒŒì¼ (CSV/JSON)
        - ê° í‰ê°€ìë³„ ë¼ë²¨ ì»¬ëŸ¼
        """)
        num_raters = st.number_input(
            "í‰ê°€ì ìˆ˜",
            min_value=2,
            max_value=10,
            value=2,
            help="ì¼ê´€ì„± í‰ê°€ë¥¼ ìœ„í•œ í‰ê°€ì ìˆ˜"
        )
        rater_files = []
        rater_names = []
        for i in range(num_raters):
            col1, col2 = st.columns([3, 1])
            with col1:
                file = st.file_uploader(
                    f"í‰ê°€ì {i+1} ë¼ë²¨ íŒŒì¼",
                    type=["csv", "json"],
                    key=f"rater_{i}"
                )
            with col2:
                name = st.text_input(f"í‰ê°€ì {i+1} ì´ë¦„", value=f"Rater{i+1}", key=f"name_{i}")
            if file:
                rater_files.append(file)
                rater_names.append(name)
        if len(rater_files) == num_raters and st.button("ì¼ê´€ì„± í‰ê°€ ì‹œì‘", type="primary"):
            try:
                import pandas as pd
                import json
                from src.quality_evaluator import evaluate_consistency
                labels_by_raters = []
                for file in rater_files:
                    if file.name.endswith('.csv'):
                        df = pd.read_csv(file)
                    else:
                        data = json.load(file)
                        df = pd.DataFrame(data) if isinstance(data, list) else pd.DataFrame([data])
                    # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ë¼ë²¨ë¡œ ì‚¬ìš© (ë˜ëŠ” ì‚¬ìš©ì ì„ íƒ)
                    label_col = df.columns[0]
                    labels = df[label_col].tolist()
                    labels_by_raters.append(labels)
                with st.spinner("ì¼ê´€ì„±ì„ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
                    consistency_results = evaluate_consistency(
                        labels_by_raters, rater_names
                    )
                st.success("í‰ê°€ ì™„ë£Œ!")
                st.subheader("ì¼ê´€ì„± í‰ê°€ ê²°ê³¼")
                if "error" in consistency_results:
                    st.error(consistency_results["error"])
                else:
                    col1, col2 = st.columns(2)
                    with col1:
                        if consistency_results.get("kappa") is not None:
                            kappa = consistency_results["kappa"]
                            threshold = 0.8
                            status = "PASS âœ…" if kappa >= threshold else "FAIL âŒ"
                            st.metric("Cohen's Kappa", f"{kappa:.3f}", delta=None)
                            st.caption(f"ì„ê³„ê°’: {threshold} | ìƒíƒœ: {status}")
                    with col2:
                        if consistency_results.get("irr") is not None:
                            irr = consistency_results["irr"]
                            threshold = 0.8
                            status = "PASS âœ…" if irr >= threshold else "FAIL âŒ"
                            st.metric("IRR", f"{irr:.3f}", delta=None)
                            st.caption(f"ì„ê³„ê°’: {threshold} | ìƒíƒœ: {status}")
                    if consistency_results.get("kappa_pairs"):
                        st.info(f"í‰ê°€ì ìŒ ìˆ˜: {consistency_results['kappa_pairs']}ê°œ")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.exception(e)
