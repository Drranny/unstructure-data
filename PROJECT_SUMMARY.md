# 🧠 AI 비정형 데이터 품질진단 프로그램 - 개발 완료 보고서

## 📋 프로젝트 개요

**프로젝트명**: AI 학습용 비정형 데이터 품질진단 프로그램  
**개발 기간**: 10일 단기 집중 프로젝트  
**개발 목적**: 텍스트 및 이미지 데이터의 품질을 자동으로 진단하고 점수화  
**프레임워크**: Streamlit 웹 애플리케이션  
**배포 환경**: 로컬 실행 (SSH 서버 연결 지원)

---

## ✅ 구현 완료된 주요 기능

### 1. **단일 파일 분석 (탭 1)**

#### 파일 업로드 및 분석
- **Step 1**: 파일 업로드
  - 지원 형식: `.txt` (텍스트), `.jpg`, `.jpeg`, `.png`, `.gif`, `.bmp` (이미지)
  - 드래그 앤 드롭 또는 파일 선택 방식

- **Step 2**: 파일 타입 선택
  - 명시적 버튼 클릭 방식 ("텍스트 파일로 분석" / "이미지 파일로 분석")
  - 파일 확장자 기반 자동 추정 및 안내

- **Step 3**: 분석 실행
  - 전용 분석 버튼 클릭 ("텍스트 품질 분석 시작" / "이미지 품질 분석 시작")
  - 실시간 분석 진행 상태 표시 (Spinner)

#### 분석 결과 표시
- **품질 지표 표**: 각 지표별 점수 (0-1 범위)
- **종합 품질 점수**: 전체 지표의 평균 점수
- **품질 등급**: A (0.8+), B (0.6+), C (0.4+), D (0.4 미만)
- **등급별 피드백**: 우수/양호/개선 필요/시급 메시지
- **상세 지표 차트**: Bar chart로 시각화
- **원본 데이터 미리보기**: 분석된 텍스트/이미지 표시

---

### 2. **데이터셋 배치 분석 (탭 2)**

#### 데이터 타입 선택
- 이미지 / 텍스트 라디오 버튼 선택

#### 데이터셋 소스 선택
- **미리 탑재된 샘플 데이터셋**
  - 이미지: CIFAR-10, Hugging Face beans, food101, cifar10, 커스텀 폴더
  - 텍스트: Hugging Face imdb, yelp_review_full, ag_news (3개)

- **Hugging Face에서 검색**
  - 인기 데이터셋 목록 자동 표시 (좌측 열)
  - 검색어 입력 및 검색 기능 (우측 열)
  - 검색 결과에서 데이터셋 ID 선택
  - 이미지/텍스트 각각의 데이터셋 목록 제공

#### 다운로드 옵션
- **샘플 개수 지정**: 10~500개 슬라이더로 선택
- **전체 데이터셋 퍼센티지**: 1~100% 슬라이더로 선택
- **전체 다운로드**: 전체 데이터셋 다운로드 옵션

#### 배치 분석 결과
- **전체 통계**: 각 품질 지표별 평균, 최소, 최대, 표준편차
- **평균 품질 점수 및 등급**
- **품질 지표 상세 차트**
- **샘플 데이터 미리보기**: 이미지 5개 / 텍스트 3개

---

## 🔬 품질 진단 알고리즘

### 텍스트 품질 진단 (`src/text_quality.py`)

#### 1. 정확성 (Accuracy)
- **방법**: 패턴 기반 오류 검사
- **검사 항목**:
  - 연속된 공백 (double space)
  - 한글/영문 혼용 패턴
  - 특수문자 비율
  - 한글 문자 비율 검증

#### 2. 중복도 (Duplication)
- **방법**: Sentence Transformer 기반 문장 유사도 분석
- **모델**: `paraphrase-multilingual-MiniLM-L12-v2` (또는 `paraphrase-MiniLM-L6-v2`)
- **알고리즘**:
  - 각 문장을 임베딩 벡터로 변환
  - 문장 간 코사인 유사도 계산
  - 평균 유사도를 역비율로 변환 (중복 많을수록 낮은 점수)

#### 3. 완전성 (Completeness)
- **방법**: 의미 있는 문장 비율 계산
- **기준**: 최소 길이 이상의 문장 비율
- **계산**: `의미있는 문장 수 / 전체 문장 수`

---

### 이미지 품질 진단 (`src/image_quality.py`)

#### 1. 해상도 (Resolution)
- **기준**: 최소 512x512 픽셀
- **계산 방식**:
  - 512x512 이상: 기본 점수 1.0
  - 종횡비 4:1 초과 시 패널티 (-10%)
  - 최소 차원 기준 점수 계산
  - 2048픽셀 이상 시 보너스 (+10%)

#### 2. 선명도 (Sharpness)
- **방법**: Laplacian Variance 알고리즘
- **절차**:
  1. 이미지를 Grayscale로 변환
  2. Laplacian 필터 적용 (엣지 감지)
  3. 분산(Variance) 계산
  4. 분산값을 0-1 점수로 정규화

#### 3. 노이즈 (Noise)
- **방법**: Gaussian Blur 차이 분석
- **절차**:
  1. 원본 이미지에 Gaussian Blur (5x5 커널) 적용
  2. 원본과 블러 이미지의 절대 차이 계산
  3. 차이의 평균값으로 노이즈 수준 측정
  4. 노이즈 수준을 점수로 변환 (노이즈 많을수록 낮은 점수)

#### 4. 중복도 (Duplication)
- **방법**: ImageHash 기반 비교
- **알고리즘**: `imagehash.average_hash` 사용
- **배치 분석 시**: 해시값 비교를 통한 중복 이미지 감지

---

## 📁 프로젝트 구조

```
unstructure/
├── app.py                          # Streamlit 메인 애플리케이션 (949줄)
├── requirements.txt                # Python 패키지 의존성 목록
│
├── src/                            # 핵심 분석 모듈
│   ├── __init__.py
│   ├── text_quality.py            # 텍스트 품질 진단 알고리즘
│   ├── image_quality.py           # 이미지 품질 진단 알고리즘
│   ├── utils.py                   # 공통 함수 (점수 계산, 등급 산출)
│   ├── dataset_analyzer.py       # 데이터셋 로드 및 배치 분석 (613줄)
│   └── dataset_finder.py         # Hugging Face 데이터셋 검색 (141줄)
│
├── sample_data/                   # 샘플 테스트 데이터
│   └── sample_text.txt
│
├── data/                          # 다운로드된 데이터셋 저장소
│   └── cifar-10-batches-py/      # CIFAR-10 데이터셋 (자동 다운로드)
│
└── 문서/
    ├── README.md                  # 프로젝트 설명서
    ├── ALGORITHM_DESCRIPTION.md   # 알고리즘 상세 설명
    ├── HUGGINGFACE_DATASETS.md    # Hugging Face 사용 가이드
    ├── SSH_SERVER_GUIDE.md       # SSH 서버 실행 가이드
    └── LOCAL_USE_ONLY.md         # 로컬 사용 가이드
```

---

## 🎨 사용자 인터페이스

### 디자인 테마
- **색상**: 화이트 & 블루 계열
- **주요 색상**:
  - 기본 블루: `#4472c4`
  - 진한 블루: `#2e75b6`
  - 다크 블루: `#1f4e79`
  - 배경: `#FFFFFF` (화이트)
  - 강조 색상: `#d9e2f3`, `#e8f0f8`

### UI 구성 요소
- **탭 구조**: 단일 파일 분석 / 데이터셋 배치 분석
- **사이드바**: 빠른 테스트 버튼
- **명시적 버튼**: 파일 타입 선택 및 분석 시작
- **인터랙티브 위젯**: 슬라이더, 라디오 버튼, 검색 입력

---

## 📦 주요 패키지 및 의존성

| 패키지 | 버전 | 용도 |
|--------|------|------|
| `streamlit` | >=1.28.0 | 웹 UI 프레임워크 |
| `opencv-python` | >=4.8.0 | 이미지 처리 (Laplacian, Gaussian Blur) |
| `numpy` | >=1.24.0 | 수치 연산 |
| `pillow` | >=10.0.0 | 이미지 로드/처리 |
| `sentence-transformers` | >=2.2.0 | 텍스트 임베딩 (중복도 분석) |
| `torch` | >=2.0.0 | 딥러닝 프레임워크 |
| `torchvision` | >=0.15.0 | CIFAR-10 데이터셋 로드 |
| `transformers` | >=4.30.0 | Hugging Face 모델 지원 |
| `datasets` | >=2.14.0 | Hugging Face 데이터셋 로드 |
| `huggingface_hub` | >=0.20.0 | 데이터셋 검색 및 목록 조회 |
| `imagehash` | >=4.3.1 | 이미지 해시 생성 (중복 검사) |
| `scikit-learn` | >=1.3.0 | 유틸리티 함수 |

---

## 🚀 핵심 기능 상세

### 데이터셋 로드 기능 (`src/dataset_analyzer.py`)

#### 이미지 데이터셋
1. **CIFAR-10** (`load_cifar10`)
   - `torchvision.datasets` 사용
   - 자동 다운로드 지원
   - 샘플 개수 지정 가능

2. **Hugging Face 이미지** (`load_huggingface_dataset`)
   - Streaming 모드 지원 (부분 다운로드)
   - 퍼센티지 기반 다운로드
   - 전체 다운로드 옵션
   - 이미지 컬럼 자동 감지

3. **커스텀 폴더** (`load_custom_dataset`)
   - 로컬 폴더에서 이미지 파일 로드
   - 지원 형식: `.jpg`, `.jpeg`, `.png`, `.gif`, `.bmp`

#### 텍스트 데이터셋
1. **Hugging Face 텍스트** (`load_huggingface_text_dataset`)
   - Streaming 모드 지원
   - 퍼센티지 기반 다운로드
   - 전체 다운로드 옵션
   - 텍스트 컬럼 자동 감지

### 데이터셋 검색 기능 (`src/dataset_finder.py`)

1. **검색 기능** (`search_huggingface_datasets`)
   - Hugging Face Hub API 사용
   - 검색어, 작업 타입, 결과 개수 필터링

2. **인기 데이터셋** (`get_popular_datasets`)
   - 인기 데이터셋 목록 조회
   - 작업 타입별 필터링

3. **미리 정의된 목록** (`get_predefined_datasets`)
   - 폴백용 하드코딩된 인기 데이터셋 목록

---

## 📊 분석 결과 형식

### 단일 파일 분석 결과
```python
{
    "정확성": 0.85,
    "중복도": 0.73,
    "완전성": 0.92
}
# 또는
{
    "해상도": 0.95,
    "선명도": 0.82,
    "노이즈": 0.88,
    "중복도": 1.0
}
```

### 배치 분석 결과 (데이터셋)
```python
{
    "평균 정확성": 0.83,
    "최소 정확성": 0.65,
    "최대 정확성": 0.95,
    "표준편차 정확성": 0.12,
    "평균 중복도": 0.71,
    ...
    "평균 종합 점수": 0.79
}
```

---

## 🎯 사용 시나리오

### 시나리오 1: 단일 텍스트 파일 분석
1. "단일 파일 분석" 탭 선택
2. `.txt` 파일 업로드
3. "텍스트 파일로 분석" 버튼 클릭
4. "텍스트 품질 분석 시작" 버튼 클릭
5. 결과 확인 (점수, 등급, 차트)

### 시나리오 2: 이미지 데이터셋 배치 분석 (미리 탑재)
1. "데이터셋 배치 분석" 탭 선택
2. 데이터 타입: "이미지" 선택
3. 데이터셋 소스: "미리 탑재된 샘플 데이터셋" 선택
4. 데이터셋: "Hugging Face: beans" 선택
5. 다운로드 방식: "샘플 개수 지정" → 100개 선택
6. "데이터셋 분석 시작" 버튼 클릭
7. 배치 분석 결과 확인

### 시나리오 3: Hugging Face 검색 후 분석
1. "데이터셋 배치 분석" 탭 선택
2. 데이터 타입: "텍스트" 선택
3. 데이터셋 소스: "Hugging Face에서 검색" 선택
4. 인기 목록 확인 (좌측) 또는 검색어 입력 (우측)
5. 검색 결과에서 데이터셋 ID 확인
6. "분석할 데이터셋 ID 입력" 필드에 ID 입력
7. 다운로드 방식 선택 및 분석 시작

---

## 🔧 기술적 특징

### 메모리 효율성
- **Streaming 모드**: Hugging Face 데이터셋을 전체 다운로드하지 않고 필요 시 로드
- **부분 다운로드**: 퍼센티지 기반 다운로드로 메모리 사용 최소화
- **배치 처리**: 데이터셋 분석 시 샘플 개수 제한 가능

### 사용자 경험
- **명시적 UI**: 파일 타입을 버튼으로 명확히 선택
- **3단계 프로세스**: 업로드 → 타입 선택 → 분석 시작
- **실시간 피드백**: 진행 상태, 에러 메시지, 성공 알림
- **시각화**: 차트 및 테이블로 결과 직관적 표시

### 확장성
- **모듈화된 구조**: 각 기능별 독립 모듈
- **Hugging Face 통합**: 다양한 데이터셋 확장 가능
- **커스텀 데이터셋**: 로컬 폴더 및 파일 지원

---

## 📝 파일별 역할

### `app.py` (949줄)
- Streamlit 웹 애플리케이션 메인 파일
- UI 레이아웃 및 사용자 인터랙션 처리
- 두 개의 탭: 단일 파일 분석 / 데이터셋 배치 분석
- 화이트 & 블루 테마 CSS 적용
- 세션 상태 관리

### `src/text_quality.py`
- 텍스트 품질 진단 알고리즘 구현
- `analyze_text_quality(text: str)` 함수
- Sentence Transformer 모델 로드 및 관리

### `src/image_quality.py`
- 이미지 품질 진단 알고리즘 구현
- `analyze_image_quality(img: Image.Image)` 함수
- OpenCV 기반 이미지 처리

### `src/utils.py`
- 공통 유틸리티 함수
- `calc_total_score()`: 종합 점수 계산
- `get_grade()`: 점수 → 등급 변환

### `src/dataset_analyzer.py` (613줄)
- 데이터셋 로드 및 배치 분석
- CIFAR-10, Hugging Face, 커스텀 폴더 지원
- 텍스트/이미지 데이터셋 배치 분석 함수
- Streaming 및 퍼센티지 다운로드 지원

### `src/dataset_finder.py` (141줄)
- Hugging Face 데이터셋 검색 기능
- 인기 데이터셋 목록 조회
- 검색 결과 필터링 및 정렬

---

## 🌟 주요 성과

### 구현 완료 사항
✅ 단일 파일 분석 기능 (텍스트/이미지)  
✅ 데이터셋 배치 분석 기능  
✅ Hugging Face 데이터셋 통합 (검색 + 다운로드)  
✅ 3가지 다운로드 방식 (샘플 개수/퍼센티지/전체)  
✅ 명시적 UI 플로우 (3단계 프로세스)  
✅ 인기 데이터셋 목록 표시  
✅ 화이트 & 블루 테마 적용  
✅ 샘플 데이터 테스트 기능  

### 기술적 성과
✅ 메모리 효율적인 Streaming 다운로드  
✅ 퍼센티지 기반 부분 다운로드  
✅ 다양한 데이터셋 소스 통합  
✅ 모듈화된 코드 구조  

---

## 🚦 실행 방법

### 로컬 실행
```bash
cd /home/yjjang/unstructure
pip install -r requirements.txt
streamlit run app.py
```

### SSH 서버 실행
```bash
# 서버에서 실행
cd /home/yjjang/unstructure
streamlit run app.py --server.headless true

# 로컬에서 포트 포워딩
ssh -L 8501:localhost:8501 사용자명@서버주소

# 브라우저에서 접속
http://localhost:8501
```

---

## 📚 추가 문서

- **ALGORITHM_DESCRIPTION.md**: 품질 진단 알고리즘 상세 설명
- **HUGGINGFACE_DATASETS.md**: Hugging Face 데이터셋 사용 가이드
- **SSH_SERVER_GUIDE.md**: SSH 서버에서 실행하는 방법
- **LOCAL_USE_ONLY.md**: 로컬 사용 가이드

---

## 💡 개발 완료 상태

### ✅ 완료된 기능
- [x] 텍스트 품질 진단 알고리즘
- [x] 이미지 품질 진단 알고리즘
- [x] 단일 파일 분석 UI
- [x] 데이터셋 배치 분석 UI
- [x] Hugging Face 데이터셋 통합
- [x] 데이터셋 검색 기능
- [x] 인기 데이터셋 목록 표시
- [x] 퍼센티지 기반 다운로드
- [x] 커스텀 폴더 지원
- [x] 화이트 & 블루 테마 적용

### 📊 코드 통계
- **총 파일 수**: 11개 (Python 파일 6개, 문서 5개)
- **총 코드 라인**: 약 2,000+ 줄
- **주요 모듈**: 5개 (`text_quality`, `image_quality`, `utils`, `dataset_analyzer`, `dataset_finder`)

---

## 🎓 프로젝트 활용 방법

### 학습 목적
- 데이터 품질 진단 개념 학습
- Streamlit 웹 앱 개발 학습
- Hugging Face 데이터셋 활용 학습

### 실무 활용
- AI 학습 데이터 품질 검증
- 데이터셋 전처리 전 품질 확인
- 품질 기준 설정 및 평가

---

**최종 업데이트**: 2024년 11월  
**개발 상태**: ✅ 완료 (프로토타입 버전)

