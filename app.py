import streamlit as st
from src.text_quality import analyze_text_quality
from src.image_quality import analyze_image_quality
from src.utils import (
    calc_total_score, 
    get_grade,
    generate_text_report_pdf,
    generate_image_report_pdf,
    generate_dataset_report_pdf
)
from datetime import datetime
from src.dataset_analyzer import (
analyze_dataset_images,
analyze_dataset_texts,
load_cifar10,
load_tid2013,
load_custom_dataset,
load_huggingface_dataset,
load_huggingface_text_dataset
)
from src.dataset_finder import (
search_huggingface_datasets,
get_popular_datasets,
get_predefined_datasets
)

st.set_page_config(
    page_title="ë¹„ì •í˜• ë°ì´í„° í’ˆì§ˆì§„ë‹¨ í”„ë¡œê·¸ë¨",
    page_icon=None,
    layout="wide"
)

#ë¸”ë£¨/í™”ì´íŠ¸í…Œë§ˆCSSì ìš©
# ë¸”ë£¨/í™”ì´íŠ¸ í…Œë§ˆ CSS ì ìš©
st.markdown("""
<style>
/*ì „ë°˜ì ì¸ë¸”ë£¨/í™”ì´íŠ¸í…Œë§ˆ*/
.main{
background-color: #FFFFFF;
}

/*ì œëª©ìŠ¤íƒ€ì¼*/
h1{
color: #1f4e79;
b der-bottom: 3px solid#4472c4;
padding-bottom: 10px;
margin-bottom: 20px;
}

h2,h3{
color: #2e75b6;
}

/*ë²„íŠ¼ìŠ¤íƒ€ì¼*/
.stButton>button{
background-color: #4472c4;
color:white;
b der: none;
b der-radius: 5px;
padding: 10px 20px;
font-weight: 500;
}

.stButton>button:hover{
background-color: #2e75b6;
}

/*ë©”íŠ¸ë¦­ì¹´ë“œìŠ¤íƒ€ì¼*/[data-testid = "stMetricValue"]{
color: #2e75b6;
font-weight: bold;
}

/*í…Œì´ë¸”í—¤ë”ìŠ¤íƒ€ì¼*/
theadth{
background-color: #d9e2f3;
color: #1f4e79;
}

/*ì„±ê³µ/ì •ë³´ë©”ì‹œì§€ìŠ¤íƒ€ì¼*/
.stSuccess{
background-color: #d9e8f5;
b der-left: 4px solid#4472c4;
}

.stInfo{
background-color: #e8f0f8;
b der-left: 4px solid#2e75b6;
}

/*ê²½ê³ ë©”ì‹œì§€*/
.stWarning{
background-color: #fff4e6;
b der-left: 4px solid#ffa500;
}

/*íƒ­ìŠ¤íƒ€ì¼*/
.stTabs[data-baseweb = "tab-list"]{
gap: 8px;
}

.stTabs[data-baseweb = "tab"]{
color: #2e75b6;
b der: 1px solid#d9e2f3;
background-color: #f5f8fb;
}

.stTabs[aria-selected = "true"]{
background-color: #4472c4;
color:white;
}

/*íŒŒì¼ì—…ë¡œë”ìŠ¤íƒ€ì¼*/
.uploadedFile{
background-color: #e8f0f8;
b der: 1px solid#d9e2f3;
}
</style>
""",unsafe_allow_html = True)

st.title("AI í•™ìŠµìš© ë¹„ì •í˜•ë°ì´í„° í’ˆì§ˆì§„ë‹¨ í”„ë¡œê·¸ë¨")
st.caption("í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ í’ˆì§ˆì ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")

#íƒ­ìƒì„±
tab1, tab2 = st.tabs(["ë‹¨ì¼ íŒŒì¼ ë¶„ì„", "ë°ì´í„°ì…‹ ë°°ì¹˜ ë¶„ì„"])

# ì‚¬ì´ë“œë°”ì— ìƒ˜í”Œ ë°ì´í„° í…ŒìŠ¤íŠ¸ ì˜µì…˜ ì¶”ê°€
with st.sidebar:
    st.header("ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")
    st.markdown("ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”!")
    
    if st.button("ìƒ˜í”Œ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸"):
        sample_text_path = "data/test_texts/sample_text.txt"
        try:
            with open(sample_text_path, "r", encoding="utf-8") as f:
                sample_text = f.read()
                st.session_state['sample_text'] = sample_text
                st.success("ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
        except FileNotFoundError:
            st.error("ìƒ˜í”Œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ========== íƒ­ 1: ë‹¨ì¼ íŒŒì¼ ë¶„ì„ ==========
with tab1:
    st.header("íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„")
    
    # Step 1: íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "Step 1: íŒŒì¼ ì„ íƒ",
        type=["txt", "jpg", "jpeg", "png", "gif", "bmp"],
        help="ë¶„ì„í•  í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”"
    )
    
    # Step 2: íŒŒì¼ íƒ€ì… ì„ íƒ
    if uploaded_file is not None:
        st.success(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
        
        # íŒŒì¼ íƒ€ì… ì¶”ì¸¡
        file_ext = uploaded_file.name.lower()
        is_text_file = file_ext.endswith('.txt')
        is_image_file = any(file_ext.endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp'])
        
        st.subheader("Step 2: íŒŒì¼ íƒ€ì… ì„ íƒ")
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë¶„ì„", use_container_width=True, type="primary" if is_text_file else "secondary"):
                st.session_state['file_type'] = 'text'
                st.session_state['uploaded_file'] = uploaded_file
                st.rerun()
        
        with col2:
            if st.button("ì´ë¯¸ì§€ íŒŒì¼ë¡œ ë¶„ì„", use_container_width=True, type="primary" if is_image_file else "secondary"):
                st.session_state['file_type'] = 'image'
                st.session_state['uploaded_file'] = uploaded_file
                st.rerun()
    
        # íŒŒì¼ íƒ€ì…ì´ ì„ íƒë˜ì—ˆëŠ”ì§€ í™•ì¸
        if 'file_type' not in st.session_state:
            if is_text_file:
                st.info("ì´ íŒŒì¼ì€ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë³´ì…ë‹ˆë‹¤. 'í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë¶„ì„' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
            elif is_image_file:
                st.info("ì´ íŒŒì¼ì€ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ë³´ì…ë‹ˆë‹¤. 'ì´ë¯¸ì§€ íŒŒì¼ë¡œ ë¶„ì„' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
            else:
                st.warning("íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íƒ€ì…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    # Step 3: ë¶„ì„ ì‹¤í–‰
    if 'file_type' in st.session_state and 'uploaded_file' in st.session_state:
        st.divider()
        st.subheader("Step 3: ë¶„ì„ ì‹¤í–‰")
        
        uploaded_file = st.session_state['uploaded_file']
        file_type = st.session_state['file_type']
    
        if file_type == 'text':
            st.info("**í…ìŠ¤íŠ¸ íŒŒì¼ ë¶„ì„ ëª¨ë“œ**")
            
            if st.button("í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                with st.spinner("í…ìŠ¤íŠ¸ í’ˆì§ˆì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    text = uploaded_file.read().decode("utf-8")
                    text_scores = analyze_text_quality(text)
                
                # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
                total = calc_total_score(text_scores)
                grade = get_grade(total)
                st.session_state['last_text_analysis'] = {
                    'scores': text_scores,
                    'total': total,
                    'grade': grade,
                    'file_name': uploaded_file.name
                }
                
                # ê²°ê³¼ í‘œì‹œ
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.subheader("ë¶„ì„ ê²°ê³¼")
                    st.dataframe(
                        text_scores,
                        use_container_width=True
                    )
                    st.text_area("ë¶„ì„ëœ í…ìŠ¤íŠ¸ ë‚´ìš©", text, height=150, disabled=True)
                
                with col2:
                    st.metric("ì¢…í•© í’ˆì§ˆ ì ìˆ˜", f"{total:.3f}")
                    st.metric("í’ˆì§ˆ ë“±ê¸‰", grade)
                    
                    if grade == "A":
                        st.success("ìš°ìˆ˜í•œ í’ˆì§ˆì…ë‹ˆë‹¤!")
                    elif grade == "B":
                        st.info("ì–‘í˜¸í•œ í’ˆì§ˆì…ë‹ˆë‹¤.")
                    elif grade == "C":
                        st.warning("ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    else:
                        st.error("í’ˆì§ˆ ê°œì„ ì´ ì‹œê¸‰í•©ë‹ˆë‹¤.")
                
                st.subheader("ìƒì„¸ í’ˆì§ˆ ì§€í‘œ ë¶„ì„")
                st.bar_chart(text_scores)
                
                # PDF ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                st.divider()
                dataset_name = uploaded_file.name if uploaded_file else None
                pdf_buffer = generate_text_report_pdf(text_scores, total, grade, dataset_name=dataset_name)
                filename = f"text_quality_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                st.download_button(
                    label="ğŸ“„ PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                    data=pdf_buffer.getvalue(),
                    file_name=filename,
                    mime="application/pdf",
                    type="primary",
                    use_container_width=True
                )
                
                # ìƒˆ ë¶„ì„ ë²„íŠ¼
                if st.button("ìƒˆ íŒŒì¼ë¡œ ë¶„ì„í•˜ê¸°"):
                    if 'file_type' in st.session_state:
                        del st.session_state['file_type']
                    if 'uploaded_file' in st.session_state:
                        del st.session_state['uploaded_file']
                    if 'last_text_analysis' in st.session_state:
                        del st.session_state['last_text_analysis']
                    st.rerun()
    
        elif file_type == 'image':
            st.info("**ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„ ëª¨ë“œ**")
            
            # ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
            from PIL import Image
            import io
            
            uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
            img = Image.open(io.BytesIO(uploaded_file.read()))
            
            col_preview, col_button = st.columns([2, 1])
            
            with col_preview:
                st.image(img, caption=f"ì—…ë¡œë“œëœ ì´ë¯¸ì§€: {uploaded_file.name}", use_container_width=True)
            
            with col_button:
                if st.button("ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                    uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                    img = Image.open(io.BytesIO(uploaded_file.read()))
                    
                    with st.spinner("ì´ë¯¸ì§€ í’ˆì§ˆì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                        image_scores = analyze_image_quality(img)
    
                    # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
                    total = calc_total_score(image_scores)
                    grade = get_grade(total)
                    st.session_state['last_image_analysis'] = {
                        'scores': image_scores,
                        'total': total,
                        'grade': grade,
                        'file_name': uploaded_file.name
                    }
    
                    # ê²°ê³¼ í‘œì‹œ
                    st.subheader("ë¶„ì„ ê²°ê³¼")
                    
                    result_col1, result_col2 = st.columns([1, 1])
                    
                    with result_col1:
                        st.dataframe(
                            image_scores,
                            use_container_width=True
                        )
                    
                    with result_col2:
                        st.metric("ì¢…í•© í’ˆì§ˆ ì ìˆ˜", f"{total:.3f}")
                        st.metric("í’ˆì§ˆ ë“±ê¸‰", grade)
                        
                        if grade == "A":
                            st.success("ìš°ìˆ˜í•œ í’ˆì§ˆì…ë‹ˆë‹¤!")
                        elif grade == "B":
                            st.info("ì–‘í˜¸í•œ í’ˆì§ˆì…ë‹ˆë‹¤.")
                        elif grade == "C":
                            st.warning("ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                        else:
                            st.error("í’ˆì§ˆ ê°œì„ ì´ ì‹œê¸‰í•©ë‹ˆë‹¤.")
                    
                    st.subheader("ìƒì„¸ í’ˆì§ˆ ì§€í‘œ ë¶„ì„")
                    st.bar_chart(image_scores)
                    
                    # PDF ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    st.divider()
                    dataset_name = uploaded_file.name if uploaded_file else None
                    pdf_buffer = generate_image_report_pdf(image_scores, total, grade, dataset_name=dataset_name)
                    filename = f"image_quality_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                    st.download_button(
                        label="ğŸ“„ PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                        data=pdf_buffer.getvalue(),
                        file_name=filename,
                        mime="application/pdf",
                        type="primary",
                        use_container_width=True
                    )
                    
                    # ìƒˆ ë¶„ì„ ë²„íŠ¼
                    if st.button("ìƒˆ íŒŒì¼ë¡œ ë¶„ì„í•˜ê¸°", use_container_width=True):
                        if 'file_type' in st.session_state:
                            del st.session_state['file_type']
                        if 'uploaded_file' in st.session_state:
                            del st.session_state['uploaded_file']
                        if 'last_image_analysis' in st.session_state:
                            del st.session_state['last_image_analysis']
                        st.rerun()
    
    # ì„¸ì…˜ì— ì €ì¥ëœ ìƒ˜í”Œ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì²˜ë¦¬
    elif 'sample_text' in st.session_state:
        st.info("**ìƒ˜í”Œ í…ìŠ¤íŠ¸ ë¶„ì„ ëª¨ë“œ**")
        text = st.session_state['sample_text']
        
        if st.button("í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
            with st.spinner("í…ìŠ¤íŠ¸ í’ˆì§ˆì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                text_scores = analyze_text_quality(text)
            
            # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
            total = calc_total_score(text_scores)
            grade = get_grade(total)
            st.session_state['last_text_analysis'] = {
                'scores': text_scores,
                'total': total,
                'grade': grade,
                'file_name': 'sample_text.txt'
            }
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.subheader("ë¶„ì„ ê²°ê³¼")
                st.dataframe(
                    text_scores,
                    use_container_width=True
                )
                st.text_area("ë¶„ì„ëœ í…ìŠ¤íŠ¸ ë‚´ìš©", text, height=150, disabled=True)
            
            with col2:
                st.metric("ì¢…í•© í’ˆì§ˆ ì ìˆ˜", f"{total:.3f}")
                st.metric("í’ˆì§ˆ ë“±ê¸‰", grade)
                
                if grade == "A":
                    st.success("ìš°ìˆ˜í•œ í’ˆì§ˆì…ë‹ˆë‹¤!")
                elif grade == "B":
                    st.info("ì–‘í˜¸í•œ í’ˆì§ˆì…ë‹ˆë‹¤.")
                elif grade == "C":
                    st.warning("ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                else:
                    st.error("í’ˆì§ˆ ê°œì„ ì´ ì‹œê¸‰í•©ë‹ˆë‹¤.")
            
            st.subheader("ìƒì„¸ í’ˆì§ˆ ì§€í‘œ ë¶„ì„")
            st.bar_chart(text_scores)
            
            # PDF ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            st.divider()
            dataset_name = st.session_state.get('last_text_analysis', {}).get('file_name', None)
            pdf_buffer = generate_text_report_pdf(text_scores, total, grade, dataset_name=dataset_name)
            filename = f"text_quality_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            st.download_button(
                label="ğŸ“„ PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                data=pdf_buffer.getvalue(),
                file_name=filename,
                mime="application/pdf",
                type="primary",
                use_container_width=True
            )
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ìƒˆ íŒŒì¼ë¡œ ë¶„ì„í•˜ê¸°"):
            if 'sample_text' in st.session_state:
                del st.session_state['sample_text']
            if 'last_text_analysis' in st.session_state:
                del st.session_state['last_text_analysis']
            st.rerun()
    
    else:
        st.info("**ì‚¬ìš© ë°©ë²•**:\n1. ìœ„ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”\n2. íŒŒì¼ íƒ€ì…(í…ìŠ¤íŠ¸/ì´ë¯¸ì§€)ì„ ì„ íƒí•˜ì„¸ìš”\n3. ë¶„ì„ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")
        st.divider()
    
# ========== íƒ­ 2: ë°ì´í„°ì…‹ ë°°ì¹˜ ë¶„ì„ ==========
with tab2:
    st.header("ë°ì´í„°ì…‹ ë°°ì¹˜ ë¶„ì„")
    st.markdown("CIFAR-10, TID2013 ë“± ë°ì´í„°ì…‹ì„ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í’ˆì§ˆì„ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # ë°ì´í„° íƒ€ì… ì„ íƒ
    data_type = st.radio(
        "ë°ì´í„° íƒ€ì…",
        ["ì´ë¯¸ì§€", "í…ìŠ¤íŠ¸"],
        horizontal=True
    )
    
    # ë°ì´í„°ì…‹ ì†ŒìŠ¤ ì„ íƒ (ë¯¸ë¦¬ íƒ‘ì¬ëœ ìƒ˜í”Œ vs Hugging Face ê²€ìƒ‰)
    dataset_source = st.radio(
        "ë°ì´í„°ì…‹ ì†ŒìŠ¤",
        ["ë¯¸ë¦¬ íƒ‘ì¬ëœ ìƒ˜í”Œ ë°ì´í„°ì…‹", "Hugging Faceì—ì„œ ê²€ìƒ‰"],
        horizontal=True,
        help="ë¯¸ë¦¬ íƒ‘ì¬ëœ ìƒ˜í”Œ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê±°ë‚˜ Hugging Faceì—ì„œ ê²€ìƒ‰í•˜ì—¬ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    
    if data_type == "ì´ë¯¸ì§€":
        if dataset_source == "ë¯¸ë¦¬ íƒ‘ì¬ëœ ìƒ˜í”Œ ë°ì´í„°ì…‹":
            dataset_option = st.selectbox(
                "ë¶„ì„í•  ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ì„ íƒ",
                [
                    "CIFAR-10 (torchvision)",
                    "Hugging Face: beans (ì½© ì§ˆë³‘ ë¶„ë¥˜)",
                    "Hugging Face: food101 (ìŒì‹ ì´ë¯¸ì§€)",
                    "Hugging Face: cifar10",
                    "TID2013 (ë¡œì»¬)",
                    "ì»¤ìŠ¤í…€ í´ë”"
                ]
            )
        else:  # Hugging Face ê²€ìƒ‰
            dataset_option = "Hugging Face: ê²€ìƒ‰"
    else:  # í…ìŠ¤íŠ¸
        if dataset_source == "ë¯¸ë¦¬ íƒ‘ì¬ëœ ìƒ˜í”Œ ë°ì´í„°ì…‹":
            dataset_option = st.selectbox(
                "ë¶„ì„í•  í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì„ íƒ",
                [
                    "Hugging Face: imdb (ì˜í™” ë¦¬ë·°)",
                    "Hugging Face: yelp_review_full (ë¦¬ë·°)",
                    "Hugging Face: ag_news (ë‰´ìŠ¤ ë¶„ë¥˜)"
                ]
            )
        else:  # Hugging Face ê²€ìƒ‰
            dataset_option = "Hugging Face: ê²€ìƒ‰"
    
    # Hugging Face ê²€ìƒ‰ì¸ ê²½ìš° ë¨¼ì € ê²€ìƒ‰ UI í‘œì‹œ
    if dataset_option == "Hugging Face: ê²€ìƒ‰":
        st.subheader("Hugging Face ë°ì´í„°ì…‹ ê²€ìƒ‰")
        
        if data_type == "ì´ë¯¸ì§€":
            # ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ì¸ê¸° ëª©ë¡ ë° ê²€ìƒ‰
            col_info, col_search = st.columns([2, 3])
            
            with col_info:
                st.markdown("### ì¸ê¸° ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ëª©ë¡")
                try:
                    popular_list = get_predefined_datasets("image-classification")
                    if popular_list:
                        st.dataframe({
                            "ë°ì´í„°ì…‹ ID": [d["id"] for d in popular_list[:20]],
                            "ì‘ì„±ì": [d.get("author", "-") for d in popular_list[:20]],
                            "ë‹¤ìš´ë¡œë“œ ìˆ˜": [f"{d.get('downloads', 0):,}" for d in popular_list[:20]],
                        },
                        use_container_width=True,
                        height=300,
                        key="img_popular_list"
                        )
                except Exception as e:
                    st.info(f"ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            
            with col_search:
                search_query = st.text_input(
                    "ê²€ìƒ‰ì–´ ì…ë ¥",
                    placeholder="ì˜ˆ: cats, dogs, classification",
                    help="ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ê²€ìƒ‰",
                    key="img_search_main"
                )
                
                if st.button("ê²€ìƒ‰", key="img_search_btn_main", use_container_width=True):
                    st.session_state['img_search_active'] = True
                
                if st.session_state.get('img_search_active', False) or search_query:
                    try:
                        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                            if search_query:
                                results = search_huggingface_datasets(
                                    query=search_query,
                                    task="image-classification",
                                    max_results=30
                                )
                            else:
                                results = get_popular_datasets(
                                    task="image-classification",
                                    max_results=30
                                )
                        
                        if results:
                            st.success(f"{len(results)}ê°œ ë°ì´í„°ì…‹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                            dataset_df = st.dataframe({
                                "ë°ì´í„°ì…‹ ID": [d["id"] for d in results],
                                "ì‘ì„±ì": [d.get("author", "-") for d in results],
                                "ë‹¤ìš´ë¡œë“œ ìˆ˜": [f"{d.get('downloads', 0):,}" for d in results],
                            },
                            use_container_width=True,
                            height=300,
                            key="img_search_results"
                            )
                            
                            # ì„ íƒëœ ë°ì´í„°ì…‹ í‘œì‹œ
                            selected_id = st.text_input(
                                "ë¶„ì„í•  ë°ì´í„°ì…‹ ID ì…ë ¥",
                                value=st.session_state.get('selected_img_dataset', ''),
                                help="ìœ„ ëª©ë¡ì—ì„œ ë°ì´í„°ì…‹ IDë¥¼ ë³µì‚¬í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”",
                                key="img_dataset_id_input"
                            )
                            if selected_id:
                                st.session_state['selected_img_dataset'] = selected_id
                        else:
                            if search_query:
                                st.warning(f"'{search_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
                            else:
                                st.info("ì¸ê¸° ë°ì´í„°ì…‹ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        else:  # í…ìŠ¤íŠ¸
            # í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¸ê¸° ëª©ë¡ ë° ê²€ìƒ‰
            col_info, col_search = st.columns([2, 3])
            
            with col_info:
                st.markdown("### ì¸ê¸° í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ ëª©ë¡")
                try:
                    popular_list = get_predefined_datasets("text-classification")
                    if popular_list:
                        st.dataframe({
                            "ë°ì´í„°ì…‹ ID": [d["id"] for d in popular_list[:20]],
                            "ì‘ì„±ì": [d.get("author", "-") for d in popular_list[:20]],
                            "ë‹¤ìš´ë¡œë“œ ìˆ˜": [f"{d.get('downloads', 0):,}" for d in popular_list[:20]],
                        },
                        use_container_width=True,
                        height=300,
                        key="text_popular_list"
                        )
                except Exception as e:
                    st.info(f"ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            
            with col_search:
                search_query = st.text_input(
                    "ê²€ìƒ‰ì–´ ì…ë ¥",
                    placeholder="ì˜ˆ: sentiment, review, classification",
                    help="í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê²€ìƒ‰",
                    key="text_search_main"
                )
                
                if st.button("ê²€ìƒ‰", key="text_search_btn_main", use_container_width=True):
                    st.session_state['text_search_active'] = True
                
                if st.session_state.get('text_search_active', False) or search_query:
                    try:
                        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                            if search_query:
                                results = search_huggingface_datasets(
                                    query=search_query,
                                    task="text-classification",
                                    max_results=30
                                )
                            else:
                                results = get_popular_datasets(
                                    task="text-classification",
                                    max_results=30
                                )
                        
                        if results:
                            st.success(f"{len(results)}ê°œ ë°ì´í„°ì…‹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                            dataset_df = st.dataframe({
                                "ë°ì´í„°ì…‹ ID": [d["id"] for d in results],
                                "ì‘ì„±ì": [d.get("author", "-") for d in results],
                                "ë‹¤ìš´ë¡œë“œ ìˆ˜": [f"{d.get('downloads', 0):,}" for d in results],
                            },
                            use_container_width=True,
                            height=300,
                            key="text_search_results"
                            )
                            
                            # ì„ íƒëœ ë°ì´í„°ì…‹ í‘œì‹œ
                            selected_id = st.text_input(
                                "ë¶„ì„í•  ë°ì´í„°ì…‹ ID ì…ë ¥",
                                value=st.session_state.get('selected_text_dataset', ''),
                                help="ìœ„ ëª©ë¡ì—ì„œ ë°ì´í„°ì…‹ IDë¥¼ ë³µì‚¬í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”",
                                key="text_dataset_id_input"
                            )
                            if selected_id:
                                st.session_state['selected_text_dataset'] = selected_id
                        else:
                            if search_query:
                                st.warning(f"'{search_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
                            else:
                                st.info("ì¸ê¸° ë°ì´í„°ì…‹ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        st.divider()
    
    # ë‹¤ìš´ë¡œë“œ ì„¤ì •
    download_mode = st.radio(
        "ë‹¤ìš´ë¡œë“œ ë°©ì‹",
        ["ìƒ˜í”Œ ê°œìˆ˜ ì§€ì •", "ì „ì²´ ë°ì´í„°ì…‹ í¼ì„¼í‹°ì§€", "ì „ì²´ ë‹¤ìš´ë¡œë“œ"],
        help="ì¼ë¶€ë§Œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥"
    )
    
    if download_mode == "ìƒ˜í”Œ ê°œìˆ˜ ì§€ì •":
        num_samples = st.slider("ë¶„ì„í•  ìƒ˜í”Œ ê°œìˆ˜", min_value=10, max_value=500, value=100, step=10)
        download_percentage = None
        download_full = False
    elif download_mode == "ì „ì²´ ë‹¤ìš´ë¡œë“œ":
        st.info("ì „ì²´ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. (ì‹œê°„ì´ ë§ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        num_samples = None
        download_percentage = None
        download_full = True
    else:  # í¼ì„¼í‹°ì§€ ëª¨ë“œ
        download_percentage = st.slider(
            "ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°ì…‹ ë¹„ìœ¨ (%)",
            min_value=1,
            max_value=100,
            value=10,
            step=1,
            help="ì˜ˆ: 10% = ì „ì²´ ë°ì´í„°ì…‹ì˜ 10%ë§Œ ë‹¤ìš´ë¡œë“œ, 100% = ì „ì²´ ë‹¤ìš´ë¡œë“œ"
        )
        if download_percentage == 100:
            st.info("100% ì„ íƒ = ì „ì²´ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ")
        num_samples = None  # í¼ì„¼í‹°ì§€ ì‚¬ìš© ì‹œ ìƒ˜í”Œ ê°œìˆ˜ëŠ” ìë™ ê³„ì‚°
        download_full = False
    
    if st.button("ë°ì´í„°ì…‹ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
        try:
            with st.spinner(f"{dataset_option} ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                images = []
                texts = []
                
                if dataset_option == "CIFAR-10 (torchvision)":
                    dataset_option = "CIFAR-10"  # ì²˜ë¦¬ ë¡œì§ í˜¸í™˜ì„±
                
                if dataset_option == "CIFAR-10":
                    if download_full:
                        # ì „ì²´ ë‹¤ìš´ë¡œë“œ: CIFAR-10ì€ ì´ 50,000ì¥
                        st.info("CIFAR-10 ì „ì²´ ë°ì´í„°ì…‹ (50,000ì¥) ë‹¤ìš´ë¡œë“œ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
                        images = load_cifar10(50000)
                    elif download_percentage:
                        # í¼ì„¼í‹°ì§€ ê¸°ë°˜: CIFAR-10ì€ ì´ 50,000ì¥ì´ë¯€ë¡œ ê³„ì‚°
                        total_cifar = 50000
                        calculated_samples = int(total_cifar * download_percentage / 100)
                        st.info(f"CIFAR-10 ë°ì´í„°ì…‹ì˜ {download_percentage}% ({calculated_samples}ì¥) ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")
                        images = load_cifar10(calculated_samples)
                    else:
                        st.info("CIFAR-10 ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. (ì²« ì‹¤í–‰ ì‹œ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤)")
                        images = load_cifar10(num_samples)
                    st.success(f"CIFAR-10 ë°ì´í„°ì…‹ {len(images)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ!")
    
                elif dataset_option == "Hugging Face: ê²€ìƒ‰":
                    # ê²€ìƒ‰ìœ¼ë¡œ ì„ íƒí•œ ë°ì´í„°ì…‹ ì‚¬ìš©
                    if data_type == "ì´ë¯¸ì§€":
                        hf_dataset_name = st.session_state.get('selected_img_dataset', '')
                        if not hf_dataset_name:
                            st.error("ë°ì´í„°ì…‹ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                            st.stop()
                        split_name = st.selectbox("Split ì„ íƒ", ["train", "test", "validation", "val"], index=0, key="img_split_search")
                    else:  # í…ìŠ¤íŠ¸
                        hf_dataset_name = st.session_state.get('selected_text_dataset', '')
                        if not hf_dataset_name:
                            st.error("ë°ì´í„°ì…‹ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                            st.stop()
                        split_name = st.selectbox("Split ì„ íƒ", ["train", "test", "validation", "val"], index=0, key="text_split_search")
                    
                    # ê²€ìƒ‰ìœ¼ë¡œ ì„ íƒí•œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
                    if download_full:
                        if data_type == "ì´ë¯¸ì§€":
                            st.info(f"{hf_dataset_name} ì „ì²´ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì‹œê°„ì´ ë§ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
                            images = load_huggingface_dataset(
                                hf_dataset_name,
                                num_samples=None,
                                split=split_name,
                                download_full=True
                            )
                            st.success(f"Hugging Face '{hf_dataset_name}' ì´ë¯¸ì§€ ë°ì´í„°ì…‹ {len(images)}ê°œ ë¡œë“œ ì™„ë£Œ!")
                        else:
                            st.info(f"{hf_dataset_name} ì „ì²´ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì‹œê°„ì´ ë§ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
                            texts = load_huggingface_text_dataset(
                                hf_dataset_name,
                                num_samples=None,
                                split=split_name,
                                download_full=True
                            )
                            st.success(f"Hugging Face '{hf_dataset_name}' í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ {len(texts)}ê°œ ë¡œë“œ ì™„ë£Œ!")
                    elif download_percentage:
                        if data_type == "ì´ë¯¸ì§€":
                            st.info(f"{hf_dataset_name} ë°ì´í„°ì…‹ì˜ {download_percentage}% ë‹¤ìš´ë¡œë“œ ì¤‘...")
                            images = load_huggingface_dataset(
                                hf_dataset_name,
                                num_samples=None,
                                split=split_name,
                                download_percentage=download_percentage
                            )
                            st.success(f"Hugging Face '{hf_dataset_name}' ì´ë¯¸ì§€ ë°ì´í„°ì…‹ {len(images)}ê°œ ë¡œë“œ ì™„ë£Œ!")
                        else:
                            st.info(f"{hf_dataset_name} ë°ì´í„°ì…‹ì˜ {download_percentage}% ë‹¤ìš´ë¡œë“œ ì¤‘...")
                            texts = load_huggingface_text_dataset(
                                hf_dataset_name,
                                num_samples=None,
                                split=split_name,
                                download_percentage=download_percentage
                            )
                            st.success(f"Hugging Face '{hf_dataset_name}' í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ {len(texts)}ê°œ ë¡œë“œ ì™„ë£Œ!")
                    else:
                        if data_type == "ì´ë¯¸ì§€":
                            st.info(f"{hf_dataset_name} ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...")
                            images = load_huggingface_dataset(
                                hf_dataset_name,
                                num_samples=num_samples,
                                split=split_name
                            )
                            st.success(f"Hugging Face '{hf_dataset_name}' ì´ë¯¸ì§€ ë°ì´í„°ì…‹ {len(images)}ê°œ ë¡œë“œ ì™„ë£Œ!")
                        else:
                            st.info(f"{hf_dataset_name} ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...")
                            texts = load_huggingface_text_dataset(
                                hf_dataset_name,
                                num_samples=num_samples,
                                split=split_name
                            )
                            st.success(f"Hugging Face '{hf_dataset_name}' í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ {len(texts)}ê°œ ë¡œë“œ ì™„ë£Œ!")
                
                elif dataset_option.startswith("Hugging Face:"):
                    hf_dataset_name = None
                    hf_text_dataset_name = None
                    split_name = "train"
                    
                    if data_type == "ì´ë¯¸ì§€":
                        if "beans" in dataset_option:
                            hf_dataset_name = "beans"
                            if download_percentage:
                                st.info(f"Beans ë°ì´í„°ì…‹ì˜ {download_percentage}% ë‹¤ìš´ë¡œë“œ ì¤‘... (ì½© ì§ˆë³‘ ë¶„ë¥˜ ì´ë¯¸ì§€)")
                            else:
                                st.info("Beans ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì½© ì§ˆë³‘ ë¶„ë¥˜ ì´ë¯¸ì§€)")
                        elif "food101" in dataset_option:
                            hf_dataset_name = "food101"
                            if download_percentage:
                                st.info(f"Food-101 ë°ì´í„°ì…‹ì˜ {download_percentage}% ë‹¤ìš´ë¡œë“œ ì¤‘... (ìŒì‹ ì´ë¯¸ì§€)")
                            else:
                                st.info("Food-101 ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (ìŒì‹ ì´ë¯¸ì§€)")
                        elif "cifar10" in dataset_option:
                            hf_dataset_name = "cifar10"
                            if download_percentage:
                                st.info(f"CIFAR-10 (Hugging Face) ë°ì´í„°ì…‹ì˜ {download_percentage}% ë‹¤ìš´ë¡œë“œ ì¤‘...")
                            else:
                                st.info("CIFAR-10 (Hugging Face) ë‹¤ìš´ë¡œë“œ ì¤‘...")
                        
                        # ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬
                        if hf_dataset_name:
                            split_name = st.selectbox("Split ì„ íƒ", ["train", "test", "validation", "val"], index=0, key="img_split_predefined")
                            if download_full:
                                images = load_huggingface_dataset(
                                    hf_dataset_name,
                                    num_samples=None,
                                    split=split_name,
                                    download_full=True
                                )
                                st.info(f"{hf_dataset_name} ì „ì²´ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì‹œê°„ì´ ë§ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
                            elif download_percentage:
                                images = load_huggingface_dataset(
                                    hf_dataset_name,
                                    num_samples=None,
                                    split=split_name,
                                    download_percentage=download_percentage
                                )
                            else:
                                images = load_huggingface_dataset(
                                    hf_dataset_name,
                                    num_samples=num_samples,
                                    split=split_name
                                )
                            st.success(f"Hugging Face '{hf_dataset_name}' ë°ì´í„°ì…‹ {len(images)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ!")
                    
                    elif data_type == "í…ìŠ¤íŠ¸":
                        if "imdb" in dataset_option:
                            hf_text_dataset_name = "imdb"
                            if download_percentage:
                                st.info(f"IMDB ë°ì´í„°ì…‹ì˜ {download_percentage}% ë‹¤ìš´ë¡œë“œ ì¤‘... (ì˜í™” ë¦¬ë·° í…ìŠ¤íŠ¸)")
                            elif download_full:
                                st.info("IMDB ì „ì²´ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì˜í™” ë¦¬ë·° í…ìŠ¤íŠ¸)")
                            else:
                                st.info("IMDB ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì˜í™” ë¦¬ë·° í…ìŠ¤íŠ¸)")
                        elif "yelp" in dataset_option:
                            hf_text_dataset_name = "yelp_review_full"
                            if download_percentage:
                                st.info(f"Yelp Review ë°ì´í„°ì…‹ì˜ {download_percentage}% ë‹¤ìš´ë¡œë“œ ì¤‘... (ë¦¬ë·° í…ìŠ¤íŠ¸)")
                            elif download_full:
                                st.info("Yelp Review ì „ì²´ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (ë¦¬ë·° í…ìŠ¤íŠ¸)")
                            else:
                                st.info("Yelp Review ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (ë¦¬ë·° í…ìŠ¤íŠ¸)")
                        elif "ag_news" in dataset_option:
                            hf_text_dataset_name = "ag_news"
                            if download_percentage:
                                st.info(f"AG News ë°ì´í„°ì…‹ì˜ {download_percentage}% ë‹¤ìš´ë¡œë“œ ì¤‘... (ë‰´ìŠ¤ ë¶„ë¥˜ í…ìŠ¤íŠ¸)")
                            elif download_full:
                                st.info("AG News ì „ì²´ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (ë‰´ìŠ¤ ë¶„ë¥˜ í…ìŠ¤íŠ¸)")
                            else:
                                st.info("AG News ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (ë‰´ìŠ¤ ë¶„ë¥˜ í…ìŠ¤íŠ¸)")
                        
                        # í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬
                        if hf_text_dataset_name:
                            split_name = st.selectbox("Split ì„ íƒ", ["train", "test", "validation", "val"], index=0, key="text_split_predefined")
                            if download_full:
                                texts = load_huggingface_text_dataset(
                                    hf_text_dataset_name,
                                    num_samples=None,
                                    split=split_name,
                                    download_full=True
                                )
                            elif download_percentage:
                                texts = load_huggingface_text_dataset(
                                    hf_text_dataset_name,
                                    num_samples=None,
                                    split=split_name,
                                    download_percentage=download_percentage
                                )
                            else:
                                texts = load_huggingface_text_dataset(
                                    hf_text_dataset_name,
                                    num_samples=num_samples,
                                    split=split_name
                                )
                            st.success(f"Hugging Face '{hf_text_dataset_name}' í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ {len(texts)}ê°œ ë¡œë“œ ì™„ë£Œ!")
    
                elif dataset_option == "TID2013 (ë¡œì»¬)":
                    # ì»¤ìŠ¤í…€ ê²½ë¡œ ì…ë ¥ ì˜µì…˜
                    use_custom_path = st.checkbox("ì»¤ìŠ¤í…€ ê²½ë¡œ ì‚¬ìš©", key="tid_custom_path")
                    custom_path = None
                    if use_custom_path:
                        custom_path = st.text_input(
                            "TID2013 ë°ì´í„°ì…‹ ê²½ë¡œ ì…ë ¥",
                            value="./data/TID2013",
                            help="TID2013 í´ë” ë˜ëŠ” reference_images í´ë”ì˜ ìƒìœ„ ê²½ë¡œ"
                        )
                    
                    # TID2013ì€ ë¡œì»¬ íŒŒì¼ì´ë¯€ë¡œ í¼ì„¼í‹°ì§€ëŠ” ìƒ˜í”Œ ê°œìˆ˜ë¡œ ë³€í™˜
                    if download_percentage:
                        # TID2013 reference ì´ë¯¸ì§€ëŠ” ë³´í†µ 25ê°œ ì •ë„
                        total_tid = 25
                        calculated_samples = max(1, int(total_tid * download_percentage / 100))
                        st.info(f"TID2013 ë°ì´í„°ì…‹ì˜ {download_percentage}% ({calculated_samples}ì¥) ë¡œë“œí•©ë‹ˆë‹¤.")
                        images = load_tid2013(calculated_samples, custom_path=custom_path if use_custom_path else None)
                    else:
                        images = load_tid2013(num_samples, custom_path=custom_path if use_custom_path else None)
                    st.success(f"TID2013 ë°ì´í„°ì…‹ {len(images)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ!")
                
                elif dataset_option == "ì»¤ìŠ¤í…€ í´ë”":
                    folder_path = st.text_input("ì´ë¯¸ì§€ í´ë” ê²½ë¡œ ì…ë ¥", value="./data/images")
                    if folder_path:
                        # ì»¤ìŠ¤í…€ í´ë”ëŠ” í¼ì„¼í‹°ì§€ ê³„ì‚°ì´ ì–´ë ¤ìš°ë¯€ë¡œ ìƒ˜í”Œ ê°œìˆ˜ ì‚¬ìš©
                        if download_percentage:
                            st.warning("ì»¤ìŠ¤í…€ í´ë”ëŠ” í¼ì„¼í‹°ì§€ ëŒ€ì‹  ìƒ˜í”Œ ê°œìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                            images = load_custom_dataset(folder_path, num_samples if num_samples else 100)
                        else:
                            images = load_custom_dataset(folder_path, num_samples)
                        st.success(f"ì»¤ìŠ¤í…€ í´ë”ì—ì„œ {len(images)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ!")
                    else:
                        st.warning("í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                        images = []
    
                # ì´ë¯¸ì§€ ë¶„ì„
                if images:
                    # ë°°ì¹˜ ë¶„ì„ ì‹¤í–‰
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    results = analyze_dataset_images(images, max_samples=num_samples)
                    
                    progress_bar.progress(100)
                    status_text.text("ë¶„ì„ ì™„ë£Œ!")
                    
                    # ê²°ê³¼ í‘œì‹œ
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("ì „ì²´ í†µê³„")
                        st.dataframe({
                            "ì§€í‘œ": list(results.keys()),
                            "ê°’": list(results.values())
                        },
                        use_container_width=True
                        )
                    
                    with col2:
                        avg_score = results.get("í‰ê·  ì¢…í•© ì ìˆ˜", 0.0)
                        grade = get_grade(avg_score)
                        
                        st.metric("í‰ê·  í’ˆì§ˆ ì ìˆ˜", f"{avg_score:.3f}")
                        st.metric("í’ˆì§ˆ ë“±ê¸‰", grade)
                        
                        if grade == "A":
                            st.success("ìš°ìˆ˜í•œ í’ˆì§ˆì˜ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤!")
                        elif grade == "B":
                            st.info("ì–‘í˜¸í•œ í’ˆì§ˆì˜ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.")
                        elif grade == "C":
                            st.warning("í’ˆì§ˆ ê°œì„ ì´ ê¶Œì¥ë©ë‹ˆë‹¤.")
                        else:
                            st.error("í’ˆì§ˆ ê°œì„ ì´ ì‹œê¸‰í•©ë‹ˆë‹¤.")
                    
                    # ìƒì„¸ ì§€í‘œ ì‹œê°í™”
                    st.subheader("í’ˆì§ˆ ì§€í‘œ ìƒì„¸")
                    
                    metrics_data = {
                        "í‰ê·  í•´ìƒë„": results["í‰ê·  í•´ìƒë„"],
                        "í‰ê·  ì„ ëª…ë„": results["í‰ê·  ì„ ëª…ë„"],
                        "í‰ê·  ë…¸ì´ì¦ˆ": results["í‰ê·  ë…¸ì´ì¦ˆ"],
                        "í‰ê·  ì¤‘ë³µë„": results["í‰ê·  ì¤‘ë³µë„"],
                    }
                    
                    st.bar_chart(metrics_data)
                    
                    # í•´ìƒë„ ë¶„í¬ ì •ë³´ í‘œì‹œ
                    if "í•´ìƒë„ ë¶„í¬" in results:
                        st.subheader("ì„ íƒëœ ì´ë¯¸ì§€ í•´ìƒë„ ì •ë³´")
                        resolution_info = results["í•´ìƒë„ ë¶„í¬"]
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("ìµœì†Œ í•´ìƒë„", resolution_info["ìµœì†Œ"])
                        with col2:
                            st.metric("ìµœëŒ€ í•´ìƒë„", resolution_info["ìµœëŒ€"])
                        with col3:
                            st.metric("í‰ê·  í•´ìƒë„", resolution_info["í‰ê· "])
                        with col4:
                            st.metric("ì¤‘ì•™ê°’ í•´ìƒë„", resolution_info["ì¤‘ì•™ê°’"])
                        
                        st.info(f"í‰ê·  í”½ì…€ ìˆ˜: {resolution_info['í‰ê·  í”½ì…€ ìˆ˜']} í”½ì…€")
                        
                        # í•´ìƒë„ ëª©ë¡ í‘œì‹œ (í™•ì¥ ê°€ëŠ¥)
                        with st.expander("ì„ íƒëœ ì´ë¯¸ì§€ë“¤ì˜ ì‹¤ì œ í•´ìƒë„ ëª©ë¡ (ì „ì²´ ë³´ê¸°)"):
                            if "í•´ìƒë„ ëª©ë¡" in results:
                                # í•´ìƒë„ë³„ ê·¸ë£¹í™”í•˜ì—¬ í‘œì‹œ
                                from collections import Counter
                                resolution_counts = Counter(results["í•´ìƒë„ ëª©ë¡"])
                                st.write("**í•´ìƒë„ë³„ ê°œìˆ˜:**")
                                for res, count in sorted(resolution_counts.items(), key=lambda x: x[1], reverse=True):
                                    st.write(f"- {res}: {count}ê°œ")
                            
                            # ì „ì²´ ëª©ë¡ë„ í‘œì‹œ
                            st.write(f"\n**ì „ì²´ {len(results.get('í•´ìƒë„ ëª©ë¡', []))}ê°œ ì´ë¯¸ì§€ í•´ìƒë„:**")
                            st.text(", ".join(results.get("í•´ìƒë„ ëª©ë¡", [])))
                    
                    # ìƒ˜í”Œ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° (ì „ì²´ í‘œì‹œ)
                    if len(images) > 0:
                        st.subheader(f"ì„ íƒëœ ì´ë¯¸ì§€ ì „ì²´ ({len(images)}ê°œ)")
                        
                        # 5ì—´ ê·¸ë¦¬ë“œë¡œ í‘œì‹œ
                        num_cols = 5
                        num_rows = (len(images) + num_cols - 1) // num_cols  # ì˜¬ë¦¼ ê³„ì‚°
                        
                        for row in range(num_rows):
                            cols = st.columns(num_cols)
                            for col_idx in range(num_cols):
                                img_idx = row * num_cols + col_idx
                                if img_idx < len(images):
                                    with cols[col_idx]:
                                        st.image(images[img_idx], use_container_width=True)
                                        if "í•´ìƒë„ ëª©ë¡" in results and img_idx < len(results["í•´ìƒë„ ëª©ë¡"]):
                                            st.caption(f"#{img_idx+1} ({results['í•´ìƒë„ ëª©ë¡'][img_idx]})")
                                        else:
                                            st.caption(f"#{img_idx+1}")
                    
                    # ê°œë³„ ì ìˆ˜ í‘œì‹œ (í† ê¸€)
                    if "ê°œë³„ ì ìˆ˜" in results and len(results["ê°œë³„ ì ìˆ˜"]) > 0:
                        with st.expander("ê°œë³„ ì´ë¯¸ì§€ ì ìˆ˜ ìƒì„¸ ë³´ê¸°", expanded=False):
                            import pandas as pd
                            
                            # ê°œë³„ ì ìˆ˜ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                            df_scores = pd.DataFrame(results["ê°œë³„ ì ìˆ˜"])
                            df_scores.index = df_scores.index + 1  # ì¸ë±ìŠ¤ë¥¼ 1ë¶€í„° ì‹œì‘
                            df_scores.index.name = "ì´ë¯¸ì§€ ë²ˆí˜¸"
                            
                            # ì •ë ¬ ì˜µì…˜ ì¶”ê°€
                            col_sort1, col_sort2 = st.columns(2)
                            with col_sort1:
                                sort_by = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["ì¢…í•©ì ìˆ˜", "í•´ìƒë„", "ì„ ëª…ë„", "ë…¸ì´ì¦ˆ", "ì¤‘ë³µë„"], key="img_sort")
                            with col_sort2:
                                sort_order = st.selectbox("ì •ë ¬ ë°©í–¥", ["ë‚´ë¦¼ì°¨ìˆœ", "ì˜¤ë¦„ì°¨ìˆœ"], key="img_order")
                            
                            ascending = (sort_order == "ì˜¤ë¦„ì°¨ìˆœ")
                            df_scores_sorted = df_scores.sort_values(by=sort_by, ascending=ascending)
                            
                            # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
                            st.dataframe(df_scores_sorted, use_container_width=True)
                            
                            # í†µê³„ ìš”ì•½
                            st.caption(f"ì´ {len(df_scores)}ê°œ ì´ë¯¸ì§€ | í‰ê·  ì¢…í•©ì ìˆ˜: {results['í‰ê·  ì¢…í•© ì ìˆ˜']:.3f} | ìµœì†Œ: {results['ìµœì†Œ ì¢…í•© ì ìˆ˜']:.3f} | ìµœëŒ€: {results['ìµœëŒ€ ì¢…í•© ì ìˆ˜']:.3f}")
                    
                    # PDF ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    st.divider()
                    pdf_buffer = generate_dataset_report_pdf(results, "ì´ë¯¸ì§€", dataset_option)
                    filename = f"image_dataset_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                    st.download_button(
                        label="ğŸ“„ PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                        data=pdf_buffer.getvalue(),
                        file_name=filename,
                        mime="application/pdf",
                        type="primary",
                        use_container_width=True
                    )
                
                # í…ìŠ¤íŠ¸ ë¶„ì„
                elif texts:
                    # ë°°ì¹˜ ë¶„ì„ ì‹¤í–‰
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    results = analyze_dataset_texts(texts, max_samples=len(texts))
                    
                    progress_bar.progress(100)
                    status_text.text("ë¶„ì„ ì™„ë£Œ!")
                    
                    # ê²°ê³¼ í‘œì‹œ
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("ì „ì²´ í†µê³„")
                        st.dataframe({
                            "ì§€í‘œ": list(results.keys()),
                            "ê°’": list(results.values())
                        },
                        use_container_width=True
                        )
                    
                    with col2:
                        avg_score = results.get("í‰ê·  ì¢…í•© ì ìˆ˜", 0.0)
                        grade = get_grade(avg_score)
                        
                        st.metric("í‰ê·  í’ˆì§ˆ ì ìˆ˜", f"{avg_score:.3f}")
                        st.metric("í’ˆì§ˆ ë“±ê¸‰", grade)
                        
                        if grade == "A":
                            st.success("ìš°ìˆ˜í•œ í’ˆì§ˆì˜ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤!")
                        elif grade == "B":
                            st.info("ì–‘í˜¸í•œ í’ˆì§ˆì˜ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.")
                        elif grade == "C":
                            st.warning("í’ˆì§ˆ ê°œì„ ì´ ê¶Œì¥ë©ë‹ˆë‹¤.")
                        else:
                            st.error("í’ˆì§ˆ ê°œì„ ì´ ì‹œê¸‰í•©ë‹ˆë‹¤.")
                    
                    # ìƒì„¸ ì§€í‘œ ì‹œê°í™” (ë©”ì¸)
                    st.subheader("í’ˆì§ˆ ì§€í‘œ ìƒì„¸")
                    
                    metrics_data = {
                        "í‰ê·  ì •í™•ì„±": results["í‰ê·  ì •í™•ì„±"],
                        "í‰ê·  ì¤‘ë³µë„": results["í‰ê·  ì¤‘ë³µë„"],
                        "í‰ê·  ì™„ì „ì„±": results["í‰ê·  ì™„ì „ì„±"],
                    }
                    
                    st.bar_chart(metrics_data)
                    
                    # ê°œë³„ ì ìˆ˜ í‘œì‹œ (í† ê¸€)
                    if "ê°œë³„ ì ìˆ˜" in results and len(results["ê°œë³„ ì ìˆ˜"]) > 0:
                        with st.expander("ê°œë³„ í…ìŠ¤íŠ¸ ì ìˆ˜ ìƒì„¸ ë³´ê¸°", expanded=False):
                            import pandas as pd
                            
                            # ê°œë³„ ì ìˆ˜ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                            df_scores = pd.DataFrame(results["ê°œë³„ ì ìˆ˜"])
                            df_scores.index = df_scores.index + 1  # ì¸ë±ìŠ¤ë¥¼ 1ë¶€í„° ì‹œì‘
                            df_scores.index.name = "í…ìŠ¤íŠ¸ ë²ˆí˜¸"
                            
                            # ì •ë ¬ ì˜µì…˜ ì¶”ê°€
                            col_sort1, col_sort2 = st.columns(2)
                            with col_sort1:
                                sort_by = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["ì¢…í•©ì ìˆ˜", "ì •í™•ì„±", "ì¤‘ë³µë„", "ì™„ì „ì„±"], key="text_sort")
                            with col_sort2:
                                sort_order = st.selectbox("ì •ë ¬ ë°©í–¥", ["ë‚´ë¦¼ì°¨ìˆœ", "ì˜¤ë¦„ì°¨ìˆœ"], key="text_order")
                            
                            ascending = (sort_order == "ì˜¤ë¦„ì°¨ìˆœ")
                            df_scores_sorted = df_scores.sort_values(by=sort_by, ascending=ascending)
                            
                            # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
                            st.dataframe(df_scores_sorted, use_container_width=True)
                            
                            # í†µê³„ ìš”ì•½
                            st.caption(f"ì´ {len(df_scores)}ê°œ í…ìŠ¤íŠ¸ | í‰ê·  ì¢…í•©ì ìˆ˜: {results['í‰ê·  ì¢…í•© ì ìˆ˜']:.3f} | ìµœì†Œ: {results['ìµœì†Œ ì¢…í•© ì ìˆ˜']:.3f} | ìµœëŒ€: {results['ìµœëŒ€ ì¢…í•© ì ìˆ˜']:.3f}")
                    
                    # ì„ íƒëœ í…ìŠ¤íŠ¸ ì „ì²´ í‘œì‹œ (í† ê¸€)
                    if len(texts) > 0:
                        with st.expander(f"ì„ íƒëœ í…ìŠ¤íŠ¸ ì „ì²´ ë³´ê¸° ({len(texts)}ê°œ)", expanded=False):
                            for i, text in enumerate(texts):
                                # ê°œë³„ ì ìˆ˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                                score_info = ""
                                if "ê°œë³„ ì ìˆ˜" in results and i < len(results["ê°œë³„ ì ìˆ˜"]):
                                    score = results["ê°œë³„ ì ìˆ˜"][i]
                                    score_info = f" | ì •í™•ì„±: {score.get('ì •í™•ì„±', 0):.3f}, ì¤‘ë³µë„: {score.get('ì¤‘ë³µë„', 0):.3f}, ì™„ì „ì„±: {score.get('ì™„ì „ì„±', 0):.3f}, ì¢…í•©: {score.get('ì¢…í•©ì ìˆ˜', 0):.3f}"
                                
                                with st.expander(f"í…ìŠ¤íŠ¸ #{i+1} (ê¸¸ì´: {len(text)}ì{score_info})", expanded=False):
                                    st.text(text[:1000] + "..." if len(text) > 1000 else text)
                    
                    # PDF ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    st.divider()
                    pdf_buffer = generate_dataset_report_pdf(results, "í…ìŠ¤íŠ¸", dataset_option)
                    filename = f"text_dataset_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
                    st.download_button(
                        label="ğŸ“„ PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                        data=pdf_buffer.getvalue(),
                        file_name=filename,
                        mime="application/pdf",
                        type="primary",
                        use_container_width=True
                    )
    
        except ImportError as e:
            st.error(f"í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n`pip install torchvision`ì„ ì‹¤í–‰í•˜ì„¸ìš”.\n\nì—ëŸ¬: {e}")
        except FileNotFoundError as e:
            st.error(f"ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nì—ëŸ¬: {e}")
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì—ëŸ¬: {e}")
            st.exception(e)
    
    # ì‚¬ìš© ê°€ì´ë“œ
    with st.expander("ë°ì´í„°ì…‹ ë¶„ì„ ê°€ì´ë“œ"):
        st.markdown("""
        ### ì§€ì› íŒŒì¼ í˜•ì‹
        - **í…ìŠ¤íŠ¸**: `.txt` íŒŒì¼
        - **ì´ë¯¸ì§€**: `.jpg`, `.jpeg`, `.png`, `.gif`, `.bmp`
        
        ### í’ˆì§ˆ ì§€í‘œ ì„¤ëª…
        #### í…ìŠ¤íŠ¸ ë°ì´í„°
        - **ì •í™•ì„±**: ì˜¤íƒˆì ë° ë§ì¶¤ë²• ì˜¤ë¥˜ ë¹„ìœ¨
        - **ì¤‘ë³µë„**: ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ ë¶„ì„ (ë‚®ì„ìˆ˜ë¡ ì¤‘ë³µ ë§ìŒ)
        - **ì™„ì „ì„±**: ì˜ë¯¸ ìˆëŠ” ë¬¸ì¥ì˜ ë¹„ìœ¨
        
        #### ì´ë¯¸ì§€ ë°ì´í„°
        - **í•´ìƒë„**: ì´ë¯¸ì§€ í¬ê¸° ê¸°ì¤€ ì¶©ì¡± ì—¬ë¶€
        - **ì„ ëª…ë„**: ì´ë¯¸ì§€ ì„ ëª…í•¨ ì •ë„ (Laplacian Variance)
        - **ë…¸ì´ì¦ˆ**: ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ìˆ˜ì¤€
        - **ì¤‘ë³µë„**: ì¤‘ë³µ ì´ë¯¸ì§€ ë¹„ìœ¨
        
        ### í’ˆì§ˆ ë“±ê¸‰
        - **A**: 0.8 ì´ìƒ (ìš°ìˆ˜)
        - **B**: 0.6 ì´ìƒ (ì–‘í˜¸)
        - **C**: 0.4 ì´ìƒ (ë³´í†µ)
        - **D**: 0.4 ë¯¸ë§Œ (ê°œì„  í•„ìš”)
        """)
    
